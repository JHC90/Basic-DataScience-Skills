{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "[Link von \"Pracitcal Statistics for Data Science\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle Pandas-DF\n",
    "wenn nicht eingelesen kann man den auch aus den Python datentypen überführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe out of own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0   tom  10\n",
      "1  nick  15\n",
      "2  juli  14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe & add Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "print(df2)\n",
    "# alternativ kann auch direkt ins df die Spalten hinzugefügt werden\n",
    "df.columns = ['Name', 'Age']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get Column names as list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Version 1########\n",
      "Name\n",
      "Age\n",
      "\n",
      "########Version 2########\n",
      "Index(['Name', 'Age'], dtype='object')\n",
      "Name\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "print('########Version 1########')\n",
    "for col in df2.columns: \n",
    "    print(col) \n",
    "print()\n",
    "print('########Version 2########')\n",
    "#Version 2 mit integrated Function\n",
    "print(df2.columns)\n",
    "print(df2.columns[0])\n",
    "print(df2.columns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Version2########\n",
      "  FirstName  Years since Birth\n",
      "0       tom                 10\n",
      "1      nick                 15\n",
      "2      juli                 14\n",
      "\n",
      "########Version2########\n",
      "  nickname  age\n",
      "0      tom   10\n",
      "1     nick   15\n",
      "2     juli   14\n",
      "\n",
      "########Version3########\n",
      "   Name  age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "newColumnList = ['FirstName', 'Years since Birth']\n",
    "df.columns = newColumnList\n",
    "print(df)\n",
    "print()\n",
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "df.rename(columns={'FirstName':'nickname', \n",
    "                   'Years since Birth':'age'}, \n",
    "                 inplace=True)\n",
    "print(df)\n",
    "print()\n",
    "print('########Version3########')\n",
    "'''\n",
    "hier wird lediglich eine Spalte geändert\n",
    "'''\n",
    "df.rename(columns={'nickname':'Name'}, \n",
    "                 inplace=True) \n",
    "print(df)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select / Reshape Data\n",
    "\n",
    "hier wollen ein unter Subset-Bilden. Ziel ist es aus einem Datensatz mit n feature einen neuen datensatz mit n-\"WelcheAnzahlAuchImmter\" zu bilden. Anders ausgedrückt, wir wollen nur bestimmte SPALTEN herauspicken. \n",
    "\n",
    "Wollen wir nur bestimmte ZEILEN auswählen, so muss man einen Filter/Subset wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./Sample-Projects//ISLR/data/islrData_advertising.csv',delimiter=',',encoding='utf-8')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version1 dropping obsolet data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTv = df.drop(['TV','radio','newspaper'], axis=1)\n",
    "print(dfTv.shape) # => es ist wichtig dass hier (200,1) und nicht (200, ) steht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2  Transform into NP & reshaping the format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTv = df['TV']\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) \n",
    "dfTv = dfTv.values.reshape(-1,1)\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "dfTv = df['TV'].values.reshape(-1,1)\n",
    "print(dfTv.shape)\n",
    "print(type(dfTv))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3 Transformin in Numpy & select multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 2:4].values\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortieren eines Vektors /SingleColumnDF/PandasSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSingleColumUNSORTED = df['TV']\n",
    "dfSingleColumSORTED = dfSingleColumUNSORTED.sort_values(ascending=True)\n",
    "#print(dfSingleColumUnsorted)\n",
    "#print(dfSingleColumSORTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortieren eines Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einzelnes Feature für Sortierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TV  radio  newspaper  sales\n",
      "0  230.1   37.8       69.2   22.1\n",
      "1   44.5   39.3       45.1   10.4\n",
      "2   17.2   45.9       69.3    9.3\n",
      "3  151.5   41.3       58.5   18.5\n",
      "4  180.8   10.8       58.4   12.9\n",
      "      TV  radio  newspaper  sales\n",
      "130  0.7   39.6        8.7    1.6\n",
      "155  4.1   11.6        5.7    3.2\n",
      "78   5.4   29.9        9.4    5.3\n",
      "56   7.3   28.1       41.4    5.5\n",
      "126  7.8   38.9       50.6    6.6\n"
     ]
    }
   ],
   "source": [
    "dfSortedforTv = df.sort_values(['TV'], ascending=True)\n",
    "print(df.head(5))\n",
    "print(dfSortedforTv.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mehrere Feature für Sortierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hat noch nicht geklappt, wenn ich das brauch hier die Solution hinzfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausprägungen eines Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier kann ich nicht mit dem Dataset von TV arbeiten, da dieses lediglich aus numerischen Weten besteht => iris und dort die art, dort gibt es nur 3 ausprägungen\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('./Sample-Projects/Iris/data/iris.data',delimiter=',',encoding='utf-8')\n",
    "iris.columns = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "<class 'list'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(iris.Species.unique())\n",
    "irisNames = list(iris['Species'].unique())\n",
    "print(irisNames)\n",
    "print(type(irisNames))\n",
    "print(len(irisNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsets / Filter\n",
    "hier wollen ein unter Subset-Bilden. Ziel ist es bspw nur die \"Iris-versicolor\" aus dem IRIS-Dataset zu haben\n",
    "Das Subset kann man sich vorstellen wie ein Filter auf die Zeilen. Möchte man die Spalten Filtern(auswahl nur bestimmter Feature so muss nur diese Auswählen)so muss nur diese Auswählen. Kluger satz. Das mach ich in diesem Notebook unter dem Punkt \"Select/Reshape Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for categorical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "['Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredforIrisVersicolor  = iris.loc[iris['Species'] == 'Iris-versicolor']\n",
    "#print(filteredforIrisVersicolor)\n",
    "print(iris.Species.unique())\n",
    "print(filteredforIrisVersicolor.Species.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for numerical Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "count     149.000000    149.000000     149.000000    149.000000\n",
      "mean        5.848322      3.051007       3.774497      1.205369\n",
      "std         0.828594      0.433499       1.759651      0.761292\n",
      "min         4.300000      2.000000       1.000000      0.100000\n",
      "25%         5.100000      2.800000       1.600000      0.300000\n",
      "50%         5.800000      3.000000       4.400000      1.300000\n",
      "75%         6.400000      3.300000       5.100000      1.800000\n",
      "max         7.900000      4.400000       6.900000      2.500000\n"
     ]
    }
   ],
   "source": [
    "print(iris.describe()) # mean SepalLengthCm  =5.848322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      149\n",
      "unique       2\n",
      "top       True\n",
      "freq       117\n",
      "Name: SepalLengthCm, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filteredSmallerThanMeanSepalLengthCM = iris['SepalLengthCm'] > 5\n",
    "print(filteredSmallerThanMeanSepalLengthCM.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same strucutre & append those => Sequential\n",
    "hier werden die DF aneinandergereiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstellen der zwei dataframes\n",
    "dataA = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "dataB = [['Jochen', 117], ['Chris', 71], ['Silvia', 5]] \n",
    "dfA = pd.DataFrame(dataA, columns = ['Name', 'Age'])\n",
    "dfB = pd.DataFrame(dataB, columns = ['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "0     tom   10\n",
      "1    nick   15\n",
      "2    juli   14\n",
      "0  Jochen  117\n",
      "1   Chris   71\n",
      "2  Silvia    5\n",
      "###################\n",
      "     Name  Age\n",
      "0     tom   10\n",
      "1    nick   15\n",
      "2    juli   14\n",
      "3  Jochen  117\n",
      "4   Chris   71\n",
      "5  Silvia    5\n"
     ]
    }
   ],
   "source": [
    "#Inteaktion des Dataframes\n",
    "dfappend = dfA.append(dfB)\n",
    "print(dfappend)\n",
    "print(\"###################\")\n",
    "\n",
    "#update index for new dataframe\n",
    "dfappend = dfappend.reset_index()\n",
    "# Drop old index column\n",
    "dfappend = dfappend.drop(columns=\"index\")\n",
    "print(dfappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same size & concat those => parallel\n",
    "hier kann man mit den Column names sich natürlich besser spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age    Name  Age\n",
      "0   tom   10  Jochen  117\n",
      "1  nick   15   Chris   71\n",
      "2  juli   14  Silvia    5\n",
      "###################\n",
      "   Name  Age ParentsName  ParentsAge\n",
      "0   tom   10      Jochen         117\n",
      "1  nick   15       Chris          71\n",
      "2  juli   14      Silvia           5\n"
     ]
    }
   ],
   "source": [
    "#II concat => next to each other => rename / Überschreiebn\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "print(dfconcat)\n",
    "print(\"###################\")\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "dfconcat.columns = ['Name', 'Age', 'ParentsName', 'ParentsAge']\n",
    "print(dfconcat)\n",
    "\n",
    "# alternative für die Spalten namen || in diesem bsp halt doof, da hier die gleiche Sturktur (= jeweils Name', 'Age' vorliegt, \n",
    "# daher ist das eher ein bsp für sequentielle verbinung nicht parallel )\n",
    "newHeader = list(list(dfA.columns) + list(dfB.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add column to dataframe with default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age ParentsName  ParentsAge  z\n",
      "0   tom   10      Jochen         117  1\n",
      "1  nick   15       Chris          71  2\n",
      "2  juli   14      Silvia           5  3\n"
     ]
    }
   ],
   "source": [
    "dfconcat[\"z\"]=1,2,3\n",
    "print(dfconcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in to dataframes an Spalten-Nummer\n",
    "besonders wichtig bei dem Teil Split von in & output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "########\n",
      "  ParentsName  ParentsAge  z\n",
      "0      Jochen         117  1\n",
      "1       Chris          71  2\n",
      "2      Silvia           5  3\n",
      "########\n",
      "0    10\n",
      "1    15\n",
      "2    14\n",
      "Name: Age, dtype: int64\n",
      "########\n",
      "   Name  Age ParentsName  ParentsAge  z\n",
      "0   tom   10      Jochen         117  1\n",
      "1  nick   15       Chris          71  2\n",
      "2  juli   14      Silvia           5  3\n"
     ]
    }
   ],
   "source": [
    "dfSplit1 = dfconcat.iloc[:, :2]\n",
    "dfSplit2 = dfconcat.iloc[:, 2:]\n",
    "dfSplit3 = dfconcat.iloc[:, 1]\n",
    "dfSplit4 = dfconcat.iloc[:, :]\n",
    "print(dfSplit1)\n",
    "print(\"########\")\n",
    "print(dfSplit2)\n",
    "print(\"########\")\n",
    "print(dfSplit3)\n",
    "print(\"########\")\n",
    "print(dfSplit4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show all possible values in column & Anzahl der möglichen Ausprägungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tom' 'nick' 'juli']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(dfconcat.Name.unique())\n",
    "dfconcat_names = list(dfconcat['Name'].unique())\n",
    "print(len(dfconcat_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset & filter\n",
    "## numeric Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# generate random Dataframe\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter einfach\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "df_filtered = df.query('a > 0')\n",
    "#print(df_filtered) #=> das gesamte df\n",
    "#print(df_filtered.a) #=>gefiltertes df und dort die spalte a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter kette = mehrere Filter auf ein DF\n",
    "df_filtered = df.query('a > 0').query('0 < b < 2')\n",
    "# print(df_filtered) => mehrere Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>favorite_color</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Willard Morris</td>\n",
       "      <td>20</td>\n",
       "      <td>blue</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al Jennings</td>\n",
       "      <td>19</td>\n",
       "      <td>blue</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omar Mullins</td>\n",
       "      <td>22</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spencer McDaniel</td>\n",
       "      <td>21</td>\n",
       "      <td>green</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  age favorite_color  grade\n",
       "0    Willard Morris   20           blue     88\n",
       "1       Al Jennings   19           blue     92\n",
       "2      Omar Mullins   22         yellow     95\n",
       "3  Spencer McDaniel   21          green     70"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {'name': ['Willard Morris', 'Al Jennings', 'Omar Mullins', 'Spencer McDaniel'],\n",
    "'age': [20, 19, 22, 21],\n",
    "'favorite_color': ['blue', 'blue', 'yellow', \"green\"],\n",
    "'grade': [88, 92, 95, 70]}\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>favorite_color</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omar Mullins</td>\n",
       "      <td>22</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  age favorite_color  grade\n",
       "2  Omar Mullins   22         yellow     95"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To select rows whose column value equals a scalar, some_value, use ==:\n",
    "df.loc[df['favorite_color'] == 'yellow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Meldung\n",
    "Ab hier brauche ich eine etwas komplexeres Datenset um klar zu machen, was ich hier tue. Die Schritte sind jedoch nach wievor unabhängig jeweils je Chunk(bzw abschnitt) unabhängig voneinander. Es geht lediglich darum die Konzepte zu verdeutlichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "carDF = pd.read_csv('./data/data_car.csv',delimiter=',',encoding='utf-8', names=labelList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basicinfo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carDF.info()\n",
    "carDF.isna().any()\n",
    "carDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredcarDF = carDF.loc[carDF['horsepower'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ersetzen von Werten // replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "carDF = carDF.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Datatype\n",
    "Es kann vorkommen dass der Datentype geändert werden muss. Hier wird im \"carDF\" direkt der Wert überschrieben. Davor müssen jedoch die NANs behandelt werden mit Imputation oder drop oder whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "carDF[['price']]=carDF[['price']].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform pandas in Numpy-Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[['Willard Morris' 20 'blue' 88]\n",
      " ['Al Jennings' 19 'blue' 92]\n",
      " ['Omar Mullins' 22 'yellow' 95]\n",
      " ['Spencer McDaniel' 21 'green' 70]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "arr = df.to_numpy()\n",
    "print(type(df))\n",
    "print(type(arr))\n",
    "print(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

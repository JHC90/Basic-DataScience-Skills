{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle Pandas-DF\n",
    "wenn nicht eingelesen kann man den auch aus den Python datentypen überführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "[Link von \"Pracitcal Statistics for Data Science\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe out of own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0   tom  10\n",
      "1  nick  15\n",
      "2  juli  14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe & add Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "print(df2)\n",
    "# alternativ kann auch direkt ins df die Spalten hinzugefügt werden\n",
    "df.columns = ['Name', 'Age']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get Column names as list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Version 1########\n",
      "Name\n",
      "Age\n",
      "\n",
      "########Version 2########\n",
      "Index(['Name', 'Age'], dtype='object')\n",
      "Name\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "print('########Version 1########')\n",
    "for col in df2.columns: \n",
    "    print(col) \n",
    "print()\n",
    "print('########Version 2########')\n",
    "#Version 2 mit integrated Function\n",
    "print(df2.columns)\n",
    "print(df2.columns[0])\n",
    "print(df2.columns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Version2########\n",
      "  FirstName  Years since Birth\n",
      "0       tom                 10\n",
      "1      nick                 15\n",
      "2      juli                 14\n",
      "\n",
      "########Version2########\n",
      "  nickname  age\n",
      "0      tom   10\n",
      "1     nick   15\n",
      "2     juli   14\n",
      "\n",
      "########Version3########\n",
      "   Name  age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "newColumnList = ['FirstName', 'Years since Birth']\n",
    "df.columns = newColumnList\n",
    "print(df)\n",
    "print()\n",
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "df.rename(columns={'FirstName':'nickname', \n",
    "                   'Years since Birth':'age'}, \n",
    "                 inplace=True)\n",
    "print(df)\n",
    "print()\n",
    "print('########Version3########')\n",
    "'''\n",
    "hier wird lediglich eine Spalte geändert\n",
    "'''\n",
    "df.rename(columns={'nickname':'Name'}, \n",
    "                 inplace=True) \n",
    "print(df)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select / Reshape Data\n",
    "Man möchte aus einem Datensatz eine spalte isoliert haben\n",
    "für die Veranschaulichung brauch ich den Datensatz von Advertisment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./Sample-Projects//ISLR/data/islrData_advertising.csv',delimiter=',',encoding='utf-8')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version1 dropping obsolet data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTv = df.drop(['TV','radio','newspaper'], axis=1)\n",
    "print(dfTv.shape) # => es ist wichtig dass hier (200,1) und nicht (200, ) steht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2  Transform into NP & reshaping the format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 1)\n",
      "(200, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "dfTv = df['TV']\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) \n",
    "dfTv = dfTv.values.reshape(-1,1)\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "dfTv = df['TV'].values.reshape(-1,1)\n",
    "print(dfTv.shape)\n",
    "print(type(dfTv))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3 Transformin in Numpy & select multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 2:4].values\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same strucutre & append those => Sequential\n",
    "hier werden die DF aneinandergereiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstellen der zwei dataframes\n",
    "dataA = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "dataB = [['Jochen', 117], ['Chris', 71], ['Silvia', 5]] \n",
    "dfA = pd.DataFrame(dataA, columns = ['Name', 'Age'])\n",
    "dfB = pd.DataFrame(dataB, columns = ['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "0     tom   10\n",
      "1    nick   15\n",
      "2    juli   14\n",
      "0  Jochen  117\n",
      "1   Chris   71\n",
      "2  Silvia    5\n",
      "###################\n",
      "     Name  Age\n",
      "0     tom   10\n",
      "1    nick   15\n",
      "2    juli   14\n",
      "3  Jochen  117\n",
      "4   Chris   71\n",
      "5  Silvia    5\n"
     ]
    }
   ],
   "source": [
    "#Inteaktion des Dataframes\n",
    "dfappend = dfA.append(dfB)\n",
    "print(dfappend)\n",
    "print(\"###################\")\n",
    "\n",
    "#update index for new dataframe\n",
    "dfappend = dfappend.reset_index()\n",
    "# Drop old index column\n",
    "dfappend = dfappend.drop(columns=\"index\")\n",
    "print(dfappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same size & concat those => parallel\n",
    "hier kann man mit den Column names sich natürlich besser spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age    Name  Age\n",
      "0   tom   10  Jochen  117\n",
      "1  nick   15   Chris   71\n",
      "2  juli   14  Silvia    5\n",
      "###################\n",
      "   Name  Age ParentsName  ParentsAge\n",
      "0   tom   10      Jochen         117\n",
      "1  nick   15       Chris          71\n",
      "2  juli   14      Silvia           5\n"
     ]
    }
   ],
   "source": [
    "#II concat => next to each other => rename / Überschreiebn\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "print(dfconcat)\n",
    "print(\"###################\")\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "dfconcat.columns = ['Name', 'Age', 'ParentsName', 'ParentsAge']\n",
    "print(dfconcat)\n",
    "\n",
    "# alternative für die Spalten namen || in diesem bsp halt doof, da hier die gleiche Sturktur (= jeweils Name', 'Age' vorliegt, \n",
    "# daher ist das eher ein bsp für sequentielle verbinung nicht parallel )\n",
    "newHeader = list(list(dfA.columns) + list(dfB.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add column to dataframe with default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age ParentsName  ParentsAge  z\n",
      "0   tom   10      Jochen         117  1\n",
      "1  nick   15       Chris          71  2\n",
      "2  juli   14      Silvia           5  3\n"
     ]
    }
   ],
   "source": [
    "dfconcat[\"z\"]=1,2,3\n",
    "print(dfconcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in to dataframes an Spalten-Nummer\n",
    "besonders wichtig bei dem Teil Split von in & output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "########\n",
      "  ParentsName  ParentsAge  z\n",
      "0      Jochen         117  1\n",
      "1       Chris          71  2\n",
      "2      Silvia           5  3\n",
      "########\n",
      "0    10\n",
      "1    15\n",
      "2    14\n",
      "Name: Age, dtype: int64\n",
      "########\n",
      "   Name  Age ParentsName  ParentsAge  z\n",
      "0   tom   10      Jochen         117  1\n",
      "1  nick   15       Chris          71  2\n",
      "2  juli   14      Silvia           5  3\n"
     ]
    }
   ],
   "source": [
    "dfSplit1 = dfconcat.iloc[:, :2]\n",
    "dfSplit2 = dfconcat.iloc[:, 2:]\n",
    "dfSplit3 = dfconcat.iloc[:, 1]\n",
    "dfSplit4 = dfconcat.iloc[:, :]\n",
    "print(dfSplit1)\n",
    "print(\"########\")\n",
    "print(dfSplit2)\n",
    "print(\"########\")\n",
    "print(dfSplit3)\n",
    "print(\"########\")\n",
    "print(dfSplit4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show all possible values in column & Anzahl der möglichen Ausprägungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tom' 'nick' 'juli']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(dfconcat.Name.unique())\n",
    "dfconcat_names = list(dfconcat['Name'].unique())\n",
    "print(len(dfconcat_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset & filter\n",
    "## numeric Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# generate random Dataframe\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter einfach\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "df_filtered = df.query('a > 0')\n",
    "#print(df_filtered) #=> das gesamte df\n",
    "#print(df_filtered.a) #=>gefiltertes df und dort die spalte a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter kette = mehrere Filter auf ein DF\n",
    "df_filtered = df.query('a > 0').query('0 < b < 2')\n",
    "# print(df_filtered) => mehrere Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>favorite_color</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Willard Morris</td>\n",
       "      <td>20</td>\n",
       "      <td>blue</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al Jennings</td>\n",
       "      <td>19</td>\n",
       "      <td>blue</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omar Mullins</td>\n",
       "      <td>22</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spencer McDaniel</td>\n",
       "      <td>21</td>\n",
       "      <td>green</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  age favorite_color  grade\n",
       "0    Willard Morris   20           blue     88\n",
       "1       Al Jennings   19           blue     92\n",
       "2      Omar Mullins   22         yellow     95\n",
       "3  Spencer McDaniel   21          green     70"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = {'name': ['Willard Morris', 'Al Jennings', 'Omar Mullins', 'Spencer McDaniel'],\n",
    "'age': [20, 19, 22, 21],\n",
    "'favorite_color': ['blue', 'blue', 'yellow', \"green\"],\n",
    "'grade': [88, 92, 95, 70]}\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>favorite_color</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Omar Mullins</td>\n",
       "      <td>22</td>\n",
       "      <td>yellow</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  age favorite_color  grade\n",
       "2  Omar Mullins   22         yellow     95"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To select rows whose column value equals a scalar, some_value, use ==:\n",
    "df.loc[df['favorite_color'] == 'yellow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Meldung\n",
    "Ab hier brauche ich eine etwas komplexeres Datenset um klar zu machen, was ich hier tue. Die Schritte sind jedoch nach wievor unabhängig jeweils je Chunk(bzw abschnitt) unabhängig voneinander. Es geht lediglich darum die Konzepte zu verdeutlichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "carDF = pd.read_csv('./data/data_car.csv',delimiter=',',encoding='utf-8', names=labelList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basicinfo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carDF.info()\n",
    "carDF.isna().any()\n",
    "carDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsets\n",
    "hier werden wir das DF horizontal schneiden, indem wir bestimmte Parameter in einem Feature mitgeben. Hierz zb alle die ein ? in dem Feature HP haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredcarDF = carDF.loc[carDF['horsepower'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ersetzen von Werten // replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "carDF = carDF.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Datatype\n",
    "Es kann vorkommen dass der Datentype geändert werden muss. Hier wird im \"carDF\" direkt der Wert überschrieben. Davor müssen jedoch die NANs behandelt werden mit Imputation oder drop oder whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "carDF[['price']]=carDF[['price']].astype('float64')\n",
    "carDF[['horsepower']]=carDF[['horsepower']].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform pandas in Numpy-Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n",
      "[['Willard Morris' 20 'blue' 88]\n",
      " ['Al Jennings' 19 'blue' 92]\n",
      " ['Omar Mullins' 22 'yellow' 95]\n",
      " ['Spencer McDaniel' 21 'green' 70]]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "arr = df.to_numpy()\n",
    "print(type(df))\n",
    "print(type(arr))\n",
    "print(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

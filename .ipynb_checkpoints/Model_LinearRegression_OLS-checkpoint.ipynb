{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics (simple )Lineare Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Stats Models vs SKLearn for Linear Regression\n",
    "https://becominghuman.ai/stats-models-vs-sklearn-for-linear-regression-f19df95ad99b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('./Sample-Projects/Iris/data/iris.data',delimiter=',',encoding='utf-8')\n",
    "iris.columns = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vertical Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['PetalLengthCm'].values.reshape(-1,1)\n",
    "y = iris['PetalWidthCm'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SK-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36608132] [[0.41633378]]\n",
      "The linear model is: Y = -0.36608 + 0.41633X\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "modelSkLearn = lm.LinearRegression()\n",
    "resultsSklearn = modelSkLearn.fit(X,y)\n",
    "print(resultsSklearn.intercept_, resultsSklearn.coef_)\n",
    "print(\"The linear model is: Y = {:.5} + {:.5}X\".format(resultsSklearn.intercept_[0], resultsSklearn.coef_[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eine Summary funktion gibt es in Sklearn nicht(im gegensatz zu statsmodel). Daher müssen die einzelnen Themne einzeln herausgefiltert werden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE & RMSE\n",
    "Dazu hätte ich hier mit Train & Test arbeiten müssen um nun mit dem Modell Predictionen zu fahren. In diesem Beispiel habe ich nur das Model gefittet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodel\n",
    "hat den vorteil, dass eine art Summary-Function inkludiert ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1841.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 20 Mar 2020</td> <th>  Prob (F-statistic):</th> <td>5.03e-85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:23:38</td>     <th>  Log-Likelihood:    </th> <td>  23.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   149</td>      <th>  AIC:               </th> <td>  -43.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   147</td>      <th>  BIC:               </th> <td>  -37.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.3661</td> <td>    0.040</td> <td>   -9.064</td> <td> 0.000</td> <td>   -0.446</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.4163</td> <td>    0.010</td> <td>   42.905</td> <td> 0.000</td> <td>    0.397</td> <td>    0.436</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.326</td> <th>  Durbin-Watson:     </th> <td>   1.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.070</td> <th>  Jarque-Bera (JB):  </th> <td>   4.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.352</td> <th>  Prob(JB):          </th> <td>  0.0824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.556</td> <th>  Cond. No.          </th> <td>    10.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.926\n",
       "Model:                            OLS   Adj. R-squared:                  0.926\n",
       "Method:                 Least Squares   F-statistic:                     1841.\n",
       "Date:                Fri, 20 Mar 2020   Prob (F-statistic):           5.03e-85\n",
       "Time:                        08:23:38   Log-Likelihood:                 23.742\n",
       "No. Observations:                 149   AIC:                            -43.48\n",
       "Df Residuals:                     147   BIC:                            -37.48\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.3661      0.040     -9.064      0.000      -0.446      -0.286\n",
       "x1             0.4163      0.010     42.905      0.000       0.397       0.436\n",
       "==============================================================================\n",
       "Omnibus:                        5.326   Durbin-Watson:                   1.461\n",
       "Prob(Omnibus):                  0.070   Jarque-Bera (JB):                4.993\n",
       "Skew:                           0.352   Prob(JB):                       0.0824\n",
       "Kurtosis:                       3.556   Cond. No.                         10.4\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X)\n",
    "modelStatsmodel = sm.OLS(y, X).fit()\n",
    "modelStatsmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wenn wir nun die Koeffizienten betrachten, sehen wir, dass diese die gleichen sind mit const = -0.3661 && x1 = 0.4163 wie beider Methode von SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle DF\n",
    "wenn nicht eingelesen kann man den auch aus den Python datentypen überführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0   tom  10\n",
      "1  nick  15\n",
      "2  juli  14\n"
     ]
    }
   ],
   "source": [
    "#Create Dataframe\n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n"
     ]
    }
   ],
   "source": [
    "#Create Dataframe & add Column names\n",
    "df2 = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get Column names as list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Age\n",
      "Index(['Name', 'Age'], dtype='object')\n",
      "<class 'pandas.core.indexes.base.Index'>\n",
      "Name\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in df2.columns: \n",
    "    print(col) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# alternative\n",
    "print(df2.columns)\n",
    "print(type(df2.columns))\n",
    "print(df2.columns[0])\n",
    "print(df2.columns[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same strucutre & append those => Sequential\n",
    "hier werden die DF aneinandergereiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstellen der zwei dataframes\n",
    "dataA = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "dataB = [['Jochen', 117], ['Chris', 71], ['Silvia', 5]] \n",
    "dfA = pd.DataFrame(dataA, columns = ['Name', 'Age'])\n",
    "dfB = pd.DataFrame(dataB, columns = ['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "0     tom   10\n",
      "1    nick   15\n",
      "2    juli   14\n",
      "0  Jochen  117\n",
      "1   Chris   71\n",
      "2  Silvia    5\n",
      "###################\n",
      "     Name  Age\n",
      "0     tom   10\n",
      "1    nick   15\n",
      "2    juli   14\n",
      "3  Jochen  117\n",
      "4   Chris   71\n",
      "5  Silvia    5\n"
     ]
    }
   ],
   "source": [
    "#Inteaktion des Dataframes\n",
    "dfappend = dfA.append(dfB)\n",
    "print(dfappend)\n",
    "print(\"###################\")\n",
    "\n",
    "#update index for new dataframe\n",
    "dfappend = dfappend.reset_index()\n",
    "# Drop old index column\n",
    "dfappend = dfappend.drop(columns=\"index\")\n",
    "print(dfappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same size & concat those => parallel\n",
    "hier kann man mit den Column names sich natürlich besser spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age    Name  Age\n",
      "0   tom   10  Jochen  117\n",
      "1  nick   15   Chris   71\n",
      "2  juli   14  Silvia    5\n",
      "###################\n",
      "   Name  Age ParentsName  ParentsAge\n",
      "0   tom   10      Jochen         117\n",
      "1  nick   15       Chris          71\n",
      "2  juli   14      Silvia           5\n"
     ]
    }
   ],
   "source": [
    "#II concat => next to each other => rename / Überschreiebn\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "print(dfconcat)\n",
    "print(\"###################\")\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "dfconcat.columns = ['Name', 'Age', 'ParentsName', 'ParentsAge']\n",
    "print(dfconcat)\n",
    "\n",
    "# alternative für die Spalten namen || in diesem bsp halt doof, da hier die gleiche Sturktur (= jeweils Name', 'Age' vorliegt, \n",
    "# daher ist das eher ein bsp für sequentielle verbinung nicht parallel )\n",
    "newHeader = list(list(dfA.columns) + list(dfB.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add column to dataframe with default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age ParentsName  ParentsAge  z\n",
      "0   tom   10      Jochen         117  1\n",
      "1  nick   15       Chris          71  2\n",
      "2  juli   14      Silvia           5  3\n"
     ]
    }
   ],
   "source": [
    "dfconcat[\"z\"]=1,2,3\n",
    "print(dfconcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in to dataframes an Spalten-Nummer\n",
    "besonders wichtig bei dem Teil Split von in & output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "########\n",
      "  ParentsName  ParentsAge  z\n",
      "0      Jochen         117  1\n",
      "1       Chris          71  2\n",
      "2      Silvia           5  3\n",
      "########\n",
      "0    10\n",
      "1    15\n",
      "2    14\n",
      "Name: Age, dtype: int64\n",
      "########\n",
      "   Name  Age ParentsName  ParentsAge  z\n",
      "0   tom   10      Jochen         117  1\n",
      "1  nick   15       Chris          71  2\n",
      "2  juli   14      Silvia           5  3\n"
     ]
    }
   ],
   "source": [
    "dfSplit1 = dfconcat.iloc[:, :2]\n",
    "dfSplit2 = dfconcat.iloc[:, 2:]\n",
    "dfSplit3 = dfconcat.iloc[:, 1]\n",
    "dfSplit4 = dfconcat.iloc[:, :]\n",
    "print(dfSplit1)\n",
    "print(\"########\")\n",
    "print(dfSplit2)\n",
    "print(\"########\")\n",
    "print(dfSplit3)\n",
    "print(\"########\")\n",
    "print(dfSplit4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show all possible values in column & Anzahl der möglichen Ausprägungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tom' 'nick' 'juli']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(dfconcat.Name.unique())\n",
    "dfconcat_names = list(dfconcat['Name'].unique())\n",
    "print(len(dfconcat_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset & filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random Dataframe\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter einfach\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "df_filtered = df.query('a > 0')\n",
    "#print(df_filtered) #=> das gesamte df\n",
    "#print(df_filtered.a) #=>gefiltertes df und dort die spalte a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter kette = mehrere Filter auf ein DF\n",
    "df_filtered = df.query('a > 0').query('0 < b < 2')\n",
    "# print(df_filtered) => mehrere Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           a         b         c\n",
      "21  0.141970  0.608863  0.652210\n",
      "22  1.750845  0.026365  0.448670\n",
      "25  1.180373  0.455540 -0.781715\n",
      "26  0.093942  1.436504  0.825090\n",
      "27  1.162528  1.568950  0.623924\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meldung\n",
    "Ab hier brauche ich eine etwas komplexeres Datenset um klar zu machen, was ich hier tue. Die Schritte sind jedoch nach wievor unabhängig jeweils je Chunk(bzw abschnitt) unabhängig voneinander. Es geht lediglich darum die Konzepte zu verdeutlichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "carDF = pd.read_csv('./data/data_car.csv',delimiter=',',encoding='utf-8', names=labelList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basicinfo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.info()\n",
    "df.isna().any()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsets\n",
    "hier werden wir das DF horizontal schneiden, indem wir bestimmte Parameter in einem Feature mitgeben. Hierz zb alle die ein ? in dem Feature HP haben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205 entries, 0 to 204\n",
      "Data columns (total 26 columns):\n",
      "symboling           205 non-null int64\n",
      "normalizedLosses    205 non-null object\n",
      "make                205 non-null object\n",
      "fuelType            205 non-null object\n",
      "aspiration          205 non-null object\n",
      "numOfDoors          205 non-null object\n",
      "bodyStyle           205 non-null object\n",
      "driveWheels         205 non-null object\n",
      "engineLocation      205 non-null object\n",
      "wheelBase           205 non-null float64\n",
      "length              205 non-null float64\n",
      "width               205 non-null float64\n",
      "height              205 non-null float64\n",
      "curbWeight          205 non-null int64\n",
      "engineType          205 non-null object\n",
      "numOfCylinders      205 non-null object\n",
      "engineSize          205 non-null int64\n",
      "fuelSystem          205 non-null object\n",
      "bore                205 non-null object\n",
      "stroke              205 non-null object\n",
      "compressionRatio    205 non-null float64\n",
      "horsepower          205 non-null object\n",
      "peakRpm             205 non-null object\n",
      "cityMpg             205 non-null int64\n",
      "highwayMpg          205 non-null int64\n",
      "price               205 non-null object\n",
      "dtypes: float64(5), int64(5), object(16)\n",
      "memory usage: 41.8+ KB\n"
     ]
    }
   ],
   "source": [
    "carDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [symboling, normalizedLosses, make, fuelType, aspiration, numOfDoors, bodyStyle, driveWheels, engineLocation, wheelBase, length, width, height, curbWeight, engineType, numOfCylinders, engineSize, fuelSystem, bore, stroke, compressionRatio, horsepower, peakRpm, cityMpg, highwayMpg, price]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_charges_filter = carDF.loc[df['horsepower'] == \"?\"]\n",
    "# df.loc[df['column_name'] == some_value]\n",
    "print(total_charges_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ersetzen von Werten // replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "carDF = carDF.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Datatype\n",
    "Es kann vorkommen dass der Datentype geändert werden muss. Hier wird im \"carDF\" direkt der Wert überschrieben. Davor müssen jedoch die NANs behandelt werden mit Imputation oder drop oder whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "carDF[['price']]=carDF[['price']].astype('float64')\n",
    "carDF[['horsepower']]=carDF[['horsepower']].astype('float64')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

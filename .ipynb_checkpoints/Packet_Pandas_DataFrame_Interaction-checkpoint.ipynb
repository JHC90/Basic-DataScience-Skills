{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "[Link von \"Pracitcal Statistics for Data Science\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstelle Pandas-DF\n",
    "wenn nicht eingelesen kann man den auch aus den Python datentypen überführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe out of own Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1\n",
      "0   tom  10\n",
      "1  nick  15\n",
      "2  juli  14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe & add Column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "   Name  Age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "print(df2)\n",
    "# alternativ kann auch direkt ins df die Spalten hinzugefügt werden\n",
    "df.columns = ['Name', 'Age']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get Column names as list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Version 1########\n",
      "Name\n",
      "Age\n",
      "\n",
      "########Version 2########\n",
      "Index(['Name', 'Age'], dtype='object')\n",
      "Name\n",
      "Age\n"
     ]
    }
   ],
   "source": [
    "print('########Version 1########')\n",
    "for col in df2.columns: \n",
    "    print(col) \n",
    "print()\n",
    "print('########Version 2########')\n",
    "#Version 2 mit integrated Function\n",
    "print(df2.columns)\n",
    "print(df2.columns[0])\n",
    "print(df2.columns[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Version2########\n",
      "  FirstName  Years since Birth\n",
      "0       tom                 10\n",
      "1      nick                 15\n",
      "2      juli                 14\n",
      "\n",
      "########Version2########\n",
      "  nickname  age\n",
      "0      tom   10\n",
      "1     nick   15\n",
      "2     juli   14\n",
      "\n",
      "########Version3########\n",
      "   Name  age\n",
      "0   tom   10\n",
      "1  nick   15\n",
      "2  juli   14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "newColumnList = ['FirstName', 'Years since Birth']\n",
    "df.columns = newColumnList\n",
    "print(df)\n",
    "print()\n",
    "print('########Version2########')\n",
    "'''\n",
    "hier werden alle spalten geändert\n",
    "'''\n",
    "df.rename(columns={'FirstName':'nickname', \n",
    "                   'Years since Birth':'age'}, \n",
    "                 inplace=True)\n",
    "print(df)\n",
    "print()\n",
    "print('########Version3########')\n",
    "'''\n",
    "hier wird lediglich eine Spalte geändert\n",
    "'''\n",
    "df.rename(columns={'nickname':'Name'}, \n",
    "                 inplace=True) \n",
    "print(df)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select / Reshape Data\n",
    "\n",
    "hier wollen ein unter Subset-Bilden. Ziel ist es aus einem Datensatz mit n feature einen neuen datensatz mit n-\"WelcheAnzahlAuchImmter\" zu bilden. Anders ausgedrückt, wir wollen nur bestimmte SPALTEN herauspicken. \n",
    "\n",
    "Wollen wir nur bestimmte ZEILEN auswählen, so muss man einen Filter/Subset wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./Sample-Projects//ISLR/data/islrData_advertising.csv',delimiter=',',encoding='utf-8')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version1 dropping obsolet data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTv = df.drop(['TV','radio','newspaper'], axis=1)\n",
    "print(dfTv.shape) # => es ist wichtig dass hier (200,1) und nicht (200, ) steht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2  Transform into NP & reshaping the format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "dfTv = df['TV']\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) \n",
    "dfTv = dfTv.values.reshape(-1,1)\n",
    "print(dfTv.shape) # => hier eben das Problem das oben bereit erwähnt wurde => (200, ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "dfTv = df['TV'].values.reshape(-1,1)\n",
    "print(dfTv.shape)\n",
    "print(type(dfTv))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3 Transformin in Numpy & select multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 2:4].values\n",
    "print(data.shape)\n",
    "print(type(data))\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortieren eines Vektors /SingleColumnDF/PandasSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSingleColumUNSORTED = df['TV']\n",
    "dfSingleColumSORTED = dfSingleColumUNSORTED.sort_values(ascending=True)\n",
    "#print(dfSingleColumUnsorted)\n",
    "#print(dfSingleColumSORTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sortieren eines Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einzelnes Feature für Sortierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TV  radio  newspaper  sales\n",
      "0  230.1   37.8       69.2   22.1\n",
      "1   44.5   39.3       45.1   10.4\n",
      "2   17.2   45.9       69.3    9.3\n",
      "3  151.5   41.3       58.5   18.5\n",
      "4  180.8   10.8       58.4   12.9\n",
      "      TV  radio  newspaper  sales\n",
      "130  0.7   39.6        8.7    1.6\n",
      "155  4.1   11.6        5.7    3.2\n",
      "78   5.4   29.9        9.4    5.3\n",
      "56   7.3   28.1       41.4    5.5\n",
      "126  7.8   38.9       50.6    6.6\n"
     ]
    }
   ],
   "source": [
    "dfSortedforTv = df.sort_values(['TV'], ascending=True)\n",
    "print(df.head(5))\n",
    "print(dfSortedforTv.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mehrere Feature für Sortierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hat noch nicht geklappt, wenn ich das brauch hier die Solution hinzfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausprägungen eines Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier kann ich nicht mit dem Dataset von TV arbeiten, da dieses lediglich aus numerischen Weten besteht => iris und dort die art, dort gibt es nur 3 ausprägungen\n",
    "import pandas as pd\n",
    "iris = pd.read_csv('./Sample-Projects/Iris/data/iris.data',delimiter=',',encoding='utf-8')\n",
    "iris.columns = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
      "<class 'list'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(iris.Species.unique())\n",
    "irisNames = list(iris['Species'].unique())\n",
    "print(irisNames)\n",
    "print(type(irisNames))\n",
    "print(len(irisNames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsets / Filter\n",
    "hier wollen ein unter Subset-Bilden. Ziel ist es bspw nur die \"Iris-versicolor\" aus dem IRIS-Dataset zu haben\n",
    "Das Subset kann man sich vorstellen wie ein Filter auf die Zeilen. Möchte man die Spalten Filtern(auswahl nur bestimmter Feature so muss nur diese Auswählen)so muss nur diese Auswählen. Kluger satz. Das mach ich in diesem Notebook unter dem Punkt \"Select/Reshape Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "['Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredforIrisVersicolor  = iris.loc[iris['Species'] == 'Iris-versicolor']\n",
    "#print(filteredforIrisVersicolor)\n",
    "print(iris.Species.unique())\n",
    "print(filteredforIrisVersicolor.Species.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same strucutre & append those => Sequential\n",
    "hier werden die DF aneinandergereiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erstellen der zwei dataframes\n",
    "dataA = [['tom', 10], ['nick', 15], ['juli', 14]] \n",
    "dataB = [['Jochen', 117], ['Chris', 71], ['Silvia', 5]] \n",
    "dfA = pd.DataFrame(dataA, columns = ['Name', 'Age'])\n",
    "dfB = pd.DataFrame(dataB, columns = ['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inteaktion des Dataframes\n",
    "dfappend = dfA.append(dfB)\n",
    "print(dfappend)\n",
    "print(\"###################\")\n",
    "\n",
    "#update index for new dataframe\n",
    "dfappend = dfappend.reset_index()\n",
    "# Drop old index column\n",
    "dfappend = dfappend.drop(columns=\"index\")\n",
    "print(dfappend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having 2 dataframes of same size & concat those => parallel\n",
    "hier kann man mit den Column names sich natürlich besser spielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#II concat => next to each other => rename / Überschreiebn\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "print(dfconcat)\n",
    "print(\"###################\")\n",
    "dfconcat = pd.concat([dfA, dfB], axis=1, sort=False)\n",
    "dfconcat.columns = ['Name', 'Age', 'ParentsName', 'ParentsAge']\n",
    "print(dfconcat)\n",
    "\n",
    "# alternative für die Spalten namen || in diesem bsp halt doof, da hier die gleiche Sturktur (= jeweils Name', 'Age' vorliegt, \n",
    "# daher ist das eher ein bsp für sequentielle verbinung nicht parallel )\n",
    "newHeader = list(list(dfA.columns) + list(dfB.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add column to dataframe with default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfconcat[\"z\"]=1,2,3\n",
    "print(dfconcat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split in to dataframes an Spalten-Nummer\n",
    "besonders wichtig bei dem Teil Split von in & output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSplit1 = dfconcat.iloc[:, :2]\n",
    "dfSplit2 = dfconcat.iloc[:, 2:]\n",
    "dfSplit3 = dfconcat.iloc[:, 1]\n",
    "dfSplit4 = dfconcat.iloc[:, :]\n",
    "print(dfSplit1)\n",
    "print(\"########\")\n",
    "print(dfSplit2)\n",
    "print(\"########\")\n",
    "print(dfSplit3)\n",
    "print(\"########\")\n",
    "print(dfSplit4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show all possible values in column & Anzahl der möglichen Ausprägungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfconcat.Name.unique())\n",
    "dfconcat_names = list(dfconcat['Name'].unique())\n",
    "print(len(dfconcat_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset & filter\n",
    "## numeric Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# generate random Dataframe\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter einfach\n",
    "df = pd.DataFrame(np.random.randn(30, 3), columns=['a','b','c'])\n",
    "df_filtered = df.query('a > 0')\n",
    "#print(df_filtered) #=> das gesamte df\n",
    "#print(df_filtered.a) #=>gefiltertes df und dort die spalte a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset & Filter kette = mehrere Filter auf ein DF\n",
    "df_filtered = df.query('a > 0').query('0 < b < 2')\n",
    "# print(df_filtered) => mehrere Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'name': ['Willard Morris', 'Al Jennings', 'Omar Mullins', 'Spencer McDaniel'],\n",
    "'age': [20, 19, 22, 21],\n",
    "'favorite_color': ['blue', 'blue', 'yellow', \"green\"],\n",
    "'grade': [88, 92, 95, 70]}\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To select rows whose column value equals a scalar, some_value, use ==:\n",
    "df.loc[df['favorite_color'] == 'yellow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Meldung\n",
    "Ab hier brauche ich eine etwas komplexeres Datenset um klar zu machen, was ich hier tue. Die Schritte sind jedoch nach wievor unabhängig jeweils je Chunk(bzw abschnitt) unabhängig voneinander. Es geht lediglich darum die Konzepte zu verdeutlichen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "labelList=['symboling','normalizedLosses','make','fuelType','aspiration','numOfDoors','bodyStyle','driveWheels','engineLocation',\n",
    "           'wheelBase','length','width','height','curbWeight','engineType','numOfCylinders','engineSize','fuelSystem','bore',\n",
    "           'stroke','compressionRatio','horsepower','peakRpm','cityMpg','highwayMpg','price']\n",
    "carDF = pd.read_csv('./data/data_car.csv',delimiter=',',encoding='utf-8', names=labelList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basicinfo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carDF.info()\n",
    "carDF.isna().any()\n",
    "carDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carDF.loc[carDF['make'] == 'audi']\n",
    "filteredcarDF = carDF.loc[carDF['horsepower'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ersetzen von Werten // replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "carDF = carDF.replace(\"?\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Datatype\n",
    "Es kann vorkommen dass der Datentype geändert werden muss. Hier wird im \"carDF\" direkt der Wert überschrieben. Davor müssen jedoch die NANs behandelt werden mit Imputation oder drop oder whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carDF[['price']]=carDF[['price']].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform pandas in Numpy-Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "arr = df.to_numpy()\n",
    "print(type(df))\n",
    "print(type(arr))\n",
    "print(arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

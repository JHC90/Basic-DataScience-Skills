{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated First Shot\n",
    "In diesem Notebook wird kein Algorithmus getunt. Durch den Automated first shot soll ein Algorithmus detektiert werden, welcher sich für die Problemstellung eignet. Dabei \"läuft\" der erste Shot jeweils mit den Default werten. Die Algorithmen, die hier am besten performen werden dann entsprechend getunt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eigene Implementierung in Beispielprojekte\n",
    "[IRIS](https://github.com/JHC90/Basic-DataScience-Skills/blob/master/Sample-Projects/Iris/Iris-WorkThrough.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('./Sample-Projects/Iris/data/iris.data',delimiter=',',encoding='utf-8')\n",
    "iris.columns = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 5)\n",
      "(45, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(iris, test_size = 0.3, random_state=5)# in this our main data is split into train and test\n",
    "# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split input output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]# taking the training data features\n",
    "train_y=train.Species# output of our training data\n",
    "test_X= test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']] # taking test data features\n",
    "test_y =test.Species   #output value of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FirstShotAutomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm  #for Support Vector Machine (SVM) Algorith\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"KNN\",\n",
    "         \"SVC\",\n",
    "         \"SVM\",\n",
    "         \"Gaussian Process\",\n",
    "         \"Decision Tree\",\n",
    "         \"Random Forest\",\n",
    "         \"Naive Bayes\",\n",
    "         \"LogisticRegression\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=2),\n",
    "    SVC(),\n",
    "    svm.SVC(),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First-Shot-Function\n",
    "'''\n",
    "Das wir bewusst in eine Function ausgelagert, da wenn mit unterschiedlich vorverarbeiteten Train&Test X darauf geschossen wird\n",
    "kann das hier varibale aufgerufen werden, vgl Iris-Ausarbeitung\n",
    "'''\n",
    "def automatedFirstShot(name, clf, train_X, train_y, test_X, test_y):\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(train_X, train_y)\n",
    "        prediction=clf.predict(test_X)\n",
    "        #print(name)\n",
    "        print(str(name) + ' hat eine Accuracy von ' + str(metrics.accuracy_score(prediction,test_y)))\n",
    "        '''print(\"Confusion-Matrix:\")\n",
    "        print(confusion_matrix(test_y,prediction))\n",
    "        print(\"Classification-Report:\")\n",
    "        print(classification_report(test_y,prediction))\n",
    "        print(\"########################\")\n",
    "        print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automatedFirstShot(names, classifiers, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abhängig was hierbei rauskommt und somit Sinn gibt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>© Datamics</em>\n",
    "# Zeitreihen Übung - Aufgaben\n",
    "\n",
    "### Folge den fett gedruckten Anweisungen. Schau dir das Lösungsvideo an, wenn du stecken bleibst!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Daten\n",
    "\n",
    "** Quelle: https://datamarket.com/data/set/22ox/monthly-milk-production-pounds-per-cow-jan-62-dec-75#!ds=22ox&display=line **\n",
    "\n",
    "**Monatliche Milchproduktion: Pfund pro Kuh. Jan 1962 - Dez 1975**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importiere Numpy, Pandas und Matplotlib **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Verwende pandas, um die csv der Datei monthly-milk-production.csv zu lesen und setze index_col='Month'. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Überprüfe den Kopf des Datenframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mache den Index zu einer Zeitreihe mit Hilfe von: **\n",
    "\n",
    "    milk.index = pd.to_datetime(milk.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Zeitreihendaten ausgeben. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "** Lass uns versuchen, den Wert der Daten eines Jahres vorherzusagen. (12 Monate oder 12 Schritte in die Zukunft) **\n",
    "\n",
    "** Erstelle einen Trainings und Test Split mittels Indexierung (Hinweis: verwende .head() oder tail() oder .iloc[]). Wir wollen keinen zufälligen Trainings und Test Split, sondern wir wollen festlegen, dass das Testset die letzten 3 Monate der Daten des Testset ist, mit allem, bevor es trainiert wird. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalierung der Daten\n",
    "\n",
    "** Verwende `sklearn.preprocessing`, um die Daten mit dem MinMaxScaler zu skalieren. Denke daran, nur `fit_transform` auf die Trainingsdaten anzuwenden und dann die Testdaten zu transformieren. Du solltest sie nicht  auf die Testdaten anpassen, sonst gehst du davon aus, dass du über das zukünftige Verhalten Bescheid weißt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Funktion\n",
    "\n",
    "** Wir brauchen eine Funktion, die Batches der Trainingsdaten einspielen kann. Wir müssen einige Dinge tun, die als Schritte in den Kommentaren der Funktion aufgeführt sind. Denke daran, die vorherige Batch-Methode aus der Vorlesung für Hinweise zu verwenden. Versuche die untenstehende Funktionsvorlage auszufüllen, dies ist ein ziemlich schwieriger Schritt, also zögere nicht, in die Lösungen zu schauen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(training_data,batch_size,steps):\n",
    "    \"\"\"\n",
    "    INPUT: Data, Batch Size, Time Steps per batch\n",
    "    OUTPUT: A tuple of y time series results. y[:,:-1] and y[:,1:]\n",
    "    \"\"\"\n",
    "    #Schritt 1: Verwende np.random.randint, um einen zufälligen \n",
    "    #Startpunktindex für die Charge festzulegen.\n",
    "    #Denke daran, dass jede Charge die gleiche Anzahl von Schritten enthält.\n",
    "    #Dies bedeutet, dass du den Startpunkt auf len(data)-Schritte beschränken solltest.\n",
    "    \n",
    "    #Schritt 2: Jetzt, da du einen Start-Index hast, müsst du die Daten von\n",
    "    #dem Zufallsstart zum Zufallsstart + Schritte indexieren. \n",
    "    #Gestalte dann diese Daten neu (1,Schritte).\n",
    "    \n",
    "    #Schritt 3: Rückgabe der Chargen. Du hast zwei Chargen, die du zurückgeben\n",
    "    #kannst:und y[:,1:]. Du musst diese in Tensoren für die RNN umformen. \n",
    "    #Abhängig von deiner Indizierung wird es entweder .reshape(-1,steps-1,1) \n",
    "    #oder .reshape(-1,steps,1) sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einrichten des RNN-Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import TensorFlow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Konstanten\n",
    "\n",
    "** Definiere die Konstanten in einer einzigen Zelle. Du benötigst folgendes (in Klammern sind die Werte, die ich in meiner Lösung verwendet habe, aber du kannst mit einigen davon spielen): **\n",
    "\n",
    "* Number of Inputs (1)\n",
    "* Number of Time Steps (12)\n",
    "* Number of Neurons per Layer (100)\n",
    "* Number of Outputs (1)\n",
    "* Learning Rate (0.003)\n",
    "* Number of Iterations for Training (4000)\n",
    "* Batch Size (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Platzhalter für X und y anlegen (Du kannst die Variablennamen ändern). Die Form für diese Platzhalter sollte [None,num_time_steps-1,num_inputs] und [None, num_time_steps-1, num_outputs] sein. Der Grund, warum wir num_time_steps-1 verwenden, ist, dass jeder dieser Schritte einen Schritt kürzer ist als die ursprüngliche Zeitschrittgröße, da wir das RNN-Netzwerk trainieren, um einen Punkt in die Zukunft vorauszusagen, basierend auf der Eingangssequenz. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle nun die RNN Layer; du hast völlige Freiheit darüber. Verwende `tf.contrib.rnn` und wähle alles was du willst aus:**\n",
    "\n",
    "OutputProjectionWrappers, BasicRNNCells, BasicLSTMCells, MultiRNNCell, GRUCell etc....\n",
    "\n",
    "*Hinweis: Beachte, dass nicht jede Kombination gut funktioniert! (Im Zweifelsfall wurde ein Outputprojection Wrapper um eine einfache LSTM-Zelle mit Relu-Aktivierung verwendet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Übergebe nun die Zellenvariable in `tf.nn.dynamic_rnn`, zusammen mit deinem ersten Platzhalter (X).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verlustfunktion und Optimierer\n",
    "\n",
    "** Erstelle eine Mean-Squared-Error-Loss-Funktion und verwende diese, um einen AdamOptimizer zu minimieren, denke daran, deine Lernrate einzugeben.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Initialisierung der globalen Variablen **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erzeuge eine Instanz von `tf.train.Saver()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session\n",
    "\n",
    "** Führe eine `tf.Session` aus, die auf den von deiner `next_batch-Funktion` erzeugten Chargen trainiert. Füge außerdem eine Verlustauswertung für jeweils 100 Trainings-Iterationen hinzu. Denke daran, dein Modell nach dem Training zu speichern.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    \n",
    "    #Code hier:\n",
    "    \n",
    "    # Speicher das Modell für später\n",
    "    saver.save(sess, \"./ex_time_series_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zukunft voraussagen (Test Daten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Zeige das test_set (die letzten 12 Monate deines kompletten Datensatzes)) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Jetzt wollen wir versuchen, diese 12 Monate Daten vorherzusagen, indem wir nur die Trainingsdaten verwenden, die wir hatten. Um dies zu tun, werden wir eine Seed-Trainingsinstanz der letzten 12 Monate der Trainingsdaten eingeben, um 12 Monate in die Zukunft vorauszusagen. Dann können wir unsere generierten 12 Monate mit unseren tatsächlichen historischen Werten aus dem Testset vergleichen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Session\n",
    "\n",
    "### Notiz: \n",
    "Erinnerne dich daran, dass unser Modell wirklich nur darauf trainiert ist, einen Zeitschritt vorauszusagen. Das Modell 12 Schritte generieren zu lassen, ist eine große Anfrage, und technisch nicht das, wozu es trainiert wurde. Betrachte dies eher als die Generierung neuer Werte, die auf einem früheren Muster basieren, anstatt zu versuchen, die Zukunft direkt vorherzusagen. Du müsstest zum Originalmodell zurückkehren und das Modell trainieren, um 12 Zeitschritte vorauszusagen, um wirklich eine höhere Genauigkeit der Testdaten zu erhalten (Was aufgrund der geringeren Größe unseres Datensatzes seine Grenzen hat).**\n",
    "\n",
    "___\n",
    "\n",
    "**Fülle den untenstehenden Sitzungscode aus, um 12 Monate Daten aus den letzten 12 Monaten des Trainingssets zu generieren. Das Schwierigste daran ist die Anpassung der Arrays mit ihren Formen und Größen. Als Hilfestellung kannst du nochmal in die Vorlesung schauen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Verwende deine Saver-Instanz, um dein gespeichertes rnn-Zeitreihenmodell wiederherzustellen.\n",
    "    saver.restore(sess, \"./ex_time_series_model\")\n",
    "\n",
    " #Code hier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Zeige das Ergebnis der Vorhersagen an.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Nimm den Teil der Ergebnisse, die erzeugten Werte, und wende *\"inverse_transform\"* auf sie an, um sie wieder in Milchproduktionswerteinheiten (Pfund pro Kuh) umzuwandeln. Auch die Ergebnisse werden neu formiert (reshape) (12,1), so dass wir sie einfach in den test_set Dataframe einfügen können.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle eine neue Spalte im test_set mit dem Namen \"Generated\" und setze diese gleich mit den generierten Ergebnissen. Dabei könntest du eine Warnung erhalten, diese kannst du jedoch ignorieren.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Schaue dir das test_set Dataframe an. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Gib beide Spalten zum Vergleich aus. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Gut gemacht!\n",
    "\n",
    "Spiele mit den Parametern und RNN-Schichten rum. Verbessert eine schnellere Lernrate mit mehr Schritten das Modell? Was ist mit GRU- oder BasicRNN-Einheiten? Was, wenn du das Originalmodell trainierst, um nicht nur einen Zeitschritt in die Zukunft vorauszusagen, sondern 3? Hier gibt es viel zu tun!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

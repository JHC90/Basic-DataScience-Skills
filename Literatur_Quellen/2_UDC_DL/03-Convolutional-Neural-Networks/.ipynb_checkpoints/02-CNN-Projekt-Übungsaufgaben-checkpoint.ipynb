{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>© Datamics</em>\n",
    "## CNN Projekt: Übung Lösungen\n",
    "\n",
    "Wir werden den CIFAR-10 Datensatz verwenden, der für die Bilderkennung sehr bekannt ist! \n",
    "\n",
    "Der CIFAR-10 Datensatz besteht aus 60000 32x32 Farbbildern in 10 Klassen, mit 6000 Bildern pro Klasse. Es gibt 50000 Trainingsbilder und 10000 Testbilder. \n",
    "\n",
    "\n",
    "Der Datensatz ist in fünf Trainingschargen und eine Testcharge mit jeweils 10000 Bildern aufgeteilt. Die Testcharge enthält genau 1000 zufällig ausgewählte Bilder aus jeder Klasse. Die Trainingschargen enthalten die restlichen Bilder in zufälliger Reihenfolge, aber einige Trainingschargen können mehr Bilder von einer Klasse als von einer anderen enthalten. Dazwischen befinden sich genau 5000 Bilder aus jeder Klasse. \n",
    "\n",
    "\n",
    "**Folge den Anweisungen in Fett. Schau dir am besten das Lösungsvideo an, falls du irgendwo stecken bleibst.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schritt 0: Die Daten einlesen\n",
    "\n",
    "** *Falls du Probleme damit hast, schau dir einfach das Lösungsvideo an. Das hat eigentlich nichts mit der Übung zu tun, sondern eher mit dem Einrichten der Daten. Bitte schaue dir zunächst das Lösungsvideo an, bevor du Fragen zur Aufgabe stellst.* **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Downloade die Daten von CIFAR hier: https://www.cs.toronto.edu/~kriz/cifar.html **\n",
    "\n",
    "** Speziell der CIFAR-10 Python Versionslink: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz **\n",
    "\n",
    "** Merke dir das Verzeichnis, in dem du die Datei speicherst! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dateipfad als String hier eintragen\n",
    "CIFAR_DIR = 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Archiv enthält die Dateien `'data_batch_1`, `data_batch_2`, ...., `data_batch_5` sowie `test_batch`. Jede dieser Dateien ist ein mit `cPickle` erzeugtes Python \"pickeld\" Objekt.\n",
    "\n",
    "** Lade die Daten. Verwende diesen Code zum laden: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Wieso sind die 'b's vor dem String? **\n",
    "\n",
    "Bytes-Literale werden immer mit 'b' oder 'B' vorangestellt; sie erzeugen eine Instanz des Bytes-Typs anstelle des str-Typs. Sie dürfen nur ASCII-Zeichen enthalten. Bytes mit einem numerischen Wert von 128 oder mehr müssen mit Escapes ausgedrückt werden.\n",
    "\n",
    "https://stackoverflow.com/questions/6269765/what-does-the-b-character-do-in-front-of-a-string-literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf diese Weise geladen, enthält jede der Batch-Dateien ein Verzeichnis mit den folgenden Elementen:\n",
    "\n",
    "* data -- ein 10000x3072 numpy Array von uint8s. Jede Zeile des Arrays speichert ein 32x32 Farbbild. Die ersten 1024 Einträge enthalten die roten Kanalwerte, die nächsten 1024 die grünen und die letzten 1024 die blauen. Das Bild wird in zeilenweiser Reihenfolge gespeichert, so dass die ersten 32 Einträge des Arrays die roten Kanalwerte der ersten Zeile des Bildes sind.\n",
    "\n",
    "* labels -- eine Liste von 10000 Nummern im Bereich von 0-9. Die Zahl am Index i gibt die Bezeichnung des i-ten Bildes in den Array-Daten an.\n",
    "\n",
    "Der Datensatz enthält eine weitere Datei namens batches.meta. Es enthält ebenfalls ein Python-Dictionary-Objekt. Es hat die folgenden Einträge:\n",
    "\n",
    "* label_names -- eine 10-Elemente-Liste, die den numerischen Beschriftungen im oben beschriebenen Beschriftungsfeld aussagekräftige Namen gibt. Zum Beispiel label_names[0] == \"Flugzeug\", label_names[1] == \"Automobil\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anzeige eines einzelnen Bildes mit matplotlib\n",
    "\n",
    "Ein einzelnes Bild aus data_batch1 mit plt.imshow() anzeigen. Dazu musst du 'reshape' und 'transpose' auf den numpy Array X = data_batch[b'data'] anwenden.\n",
    "\n",
    "** Das sollte dann so aussehen: **\n",
    "\n",
    "    # Array mit allen umgewandelten und zu Ausgabe formattierten Bilder:\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setzte hier den Code ein!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X[0]/255).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilfsfunktionen für den Umgang mit Daten.\n",
    "\n",
    "** Sobald du bereit bist, die Diagrammsitzung zu erstellen, kannst du den unten angegebenen Code benutzen, um die nächste Charge zu erfassen.\n",
    "Kannst du die Funktionsweise erklären?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=10):\n",
    "    '''\n",
    "    Verwende die One-Hot-Encodierung der 10 möglichen Labels. \n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "        self.test_batch = [test_batch]\n",
    "        \n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Einrichten von Trainingsbildern und Labels\")\n",
    "        \n",
    "        # Reiht die Trainingsbilder vertikal auf\n",
    "        self.training_images = np.vstack([d[b\"data\"] for d in self.all_train_batches])\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        # Reshapes und normalisiert die Trainingsdaten\n",
    "        self.training_images = self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        self.training_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches]), 10)\n",
    "        \n",
    "        print(\"Einrichten von Testbildern und Labels\")\n",
    "        \n",
    "        # Reiht die Testbilder vertikal auf\n",
    "        self.test_images = np.vstack([d[b\"data\"] for d in self.test_batch])\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        # Reshapes und normalisiert die Trainingsdaten\n",
    "        self.test_images = self.test_images.reshape(test_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        \n",
    "        # One-hot Encodierung der Testlabels (z.B. [0,0,0,1,0,0,0,0,0,0])\n",
    "        self.test_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.test_batch]), 10)\n",
    "\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        # Die 100 Dimensionen des Reshape Aufrufs basiert auf der Annnahme einer Batch-Size von 100!\n",
    "        x = self.training_images[self.i:self.i+batch_size].reshape(100,32,32,3)\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Wie man den obigen Code benutzt: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Führe vor deiner tf.Session die folgende zwei Zeilen aus\n",
    "ch = CifarHelper()\n",
    "ch.set_up_images()\n",
    "\n",
    "# Verwende diese Zeilen während der Sitzung, um die nächste Charge zu holen.\n",
    "# (Genau wie bei mnist.train.next_batch)\n",
    "# batch = ch.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Modell erstellen\n",
    "\n",
    "** Import tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle zwei Platzhalter x und y_true. Ihre Formen sollten wie folgt sein:** \n",
    "\n",
    "\n",
    "* x shape = [None,32,32,3]\n",
    "* y_true shape = [None,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle einen weiteren Platzhalter namens hold_prob. Hier besteht keine Notwendigkeit für eine Form (en. shape). Dieser Platzhalter enthält nur eine einzige Wahrscheinlichkeit für den Abbruch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helfer-Funktionen\n",
    "\n",
    "** Hole dir die Hilfsfunktionen von MNIST mit CNN.**\n",
    "\n",
    "*Hinweis: Wenn du eine Herausforderung möchtest, kannst du auch probieren hier eine Hilfsfunktion selbst zu erstellen.*\n",
    "\n",
    "Du wirst folgendes brauchen:\n",
    "\n",
    "* init_weights\n",
    "* init_bias\n",
    "* conv2d\n",
    "* max_pool_2by2\n",
    "* convolutional_layer\n",
    "* normal_full_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstelle die Layers\n",
    "\n",
    "** Erstelle eine Convolutional Layer und eine Pooling Layer wie bei MNIST.**\n",
    "\n",
    "Es liegt an dir, wie groß die Convolution sein soll, aber die letzten beiden Ziffern müssen wegen der 3 Farbkanäle und 32 Pixel 3 und 32 sein. Du könntest zum Beispiel folgendes verwenden:\n",
    "\n",
    "        convo_1 = convolutional_layer(x,shape=[4,4,3,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle die nächsten Convolutions- und Pooling-Layers.  Die letzten beiden Dimensionen der convo_2-Schicht sollten 32,64 sein.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle nun eine abgeflachte Layer, indem du die Pooling-Ebene in [-1,8 \\* 8 \\* 64] or [-1,4096] umwandelst.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8*8*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle nun eine neue volle Ebene mit der Funktion `normal_full_layer` und übergebe sie in ihrer flattend Convolution Layer 2 mit size=1024.**\n",
    "\n",
    "*Hinweis: Du kannst dies auch auf etwa 512 reduzieren*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle nun eine Dropout-Layer mit `tf.nn.dropout`. Denke daran, deinen `hold_prob` Platzhalter zu übergeben.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Zuletzt setz die Ausgabe auf `y_pred`, indem du die Dropout-Layer in die Funktion `normal_full_layer` übergibst. Die Größe sollte wegen der 10 möglichen Labels 10 sein.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "\n",
    "** Erstelle eine `cross_entropy` Verlustfunktion **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "** Erstelle den Optimierer mit dem AdamOptimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle eine Variable, um alle globalen tf-Variablen zu initialisieren.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Session\n",
    "\n",
    "** Führe die Trainings- und Testausdrucke in einer Tf-Sitzung durch und führe dein Modell aus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gut gemacht!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

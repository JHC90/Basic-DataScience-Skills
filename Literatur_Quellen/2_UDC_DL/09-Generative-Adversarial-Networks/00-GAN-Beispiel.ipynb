{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>Â© Datamics</em>\n",
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1b9e9c7674f9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From Z:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From Z:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From Z:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From Z:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From Z:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1daafaf69e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[5].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Das Netzwerk\n",
    "\n",
    "Hilfreiche Links:\n",
    "\n",
    "https://stackoverflow.com/questions/45307072/using-leaky-relu-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse): \n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        hidden1 = tf.nn.leaky_relu(hidden1, alpha=0.01)\n",
    "        \n",
    "        # Alternative fÃ¼r Leaky Relu Aktivierungsfunktion:\n",
    "        # hidden1 = tf.maximum(0.01*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.nn.leaky_relu(hidden2, alpha=0.01)\n",
    "        \n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh) \n",
    "\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Diskriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        # Leaky Relu\n",
    "        hidden1 = tf.nn.leaky_relu(hidden1, alpha=0.01)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.nn.leaky_relu(hidden2, alpha=0.01)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1) # Echte Daten oder gefÃ¤lscht  0 oder 1 \n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platzhalter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-1a288453539d>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From Z:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"gen/dense/kernel:0\", shape=(100, 128), dtype=float32_ref) must be from the same graph as Tensor(\"Placeholder_1:0\", shape=(?, 100), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2b1bd1678c22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-1a288453539d>\u001b[0m in \u001b[0;36mgenerator\u001b[1;34m(z, reuse)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gen'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 _reuse=reuse)\n\u001b[1;32m--> 188\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \"\"\"\n\u001b[1;32m-> 1227\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5330\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   5331\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5332\u001b[1;33m                   name=name)\n\u001b[0m\u001b[0;32m   5333\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5334\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[1;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   5711\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5712\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5713\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5714\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5715\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   5647\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5648\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[1;32m-> 5649\u001b[1;33m                                                                 original_item))\n\u001b[0m\u001b[0;32m   5650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"gen/dense/kernel:0\", shape=(100, 128), dtype=float32_ref) must be from the same graph as Tensor(\"Placeholder_1:0\", shape=(?, 100), dtype=float32)."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diskriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verlustfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.9)) \n",
    "tf.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ein Sample pro Epoche speichern\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall eine Epoche ist ein ganzer Lauf durch die Trainingsdaten\n",
    "    for e in range(epochs):\n",
    "        # // zeigt die klassische Einteilung\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Batch von Bildern erfassen\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Bilder holen, umgestalten und skalieren, um sie an D zu Ã¼bergeben.\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (zufÃ¤llige latente Rauschdaten fÃ¼r den Generator)\n",
    "            # -1 bis 1 wegen der tanh Aktivierung\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Optimierer laufen lassen, keine Notwendigkeit die Ausgaben zu speichern, wir werden sie nicht verwenden.\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Gerade bei Epoche {} von {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Ausschnitt aus dem Generator wÃ¤hrend des Trainings zur anschlieÃenden Betrachtung\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "#         saver.save(sess, './models/500_epoch_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/500_epoch_model.ckpt')\n",
    "    \n",
    "    for x in range(5):\n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples[0].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>© Datamics</em>\n",
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16e0b550f98>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUIQfCIrwA0H9PybrhDCgN402AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e0ab6a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[5].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Das Netzwerk\n",
    "\n",
    "Hilfreiche Links:\n",
    "\n",
    "https://stackoverflow.com/questions/45307072/using-leaky-relu-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse): \n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        hidden1 = tf.nn.leaky_relu(hidden1, alpha=0.01)\n",
    "        \n",
    "        # Alternative für Leaky Relu Aktivierungsfunktion:\n",
    "        # hidden1 = tf.maximum(0.01*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.nn.leaky_relu(hidden2, alpha=0.01)\n",
    "        \n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh) \n",
    "\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Diskriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        # Leaky Relu\n",
    "        hidden1 = tf.nn.leaky_relu(hidden1, alpha=0.01)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.nn.leaky_relu(hidden2, alpha=0.01)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1) # Echte Daten oder gefälscht  0 oder 1 \n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platzhalter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input graph and Layer graph are not the same: Tensor(\"Placeholder_3:0\", shape=(?, 100), dtype=float32) is not from the passed-in graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   4264\u001b[0m         raise ValueError(\n\u001b[1;32m-> 4265\u001b[1;33m             \"%s is not from the passed-in graph.\" % graph_element)\n\u001b[0m\u001b[0;32m   4266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"Placeholder_3:0\", shape=(?, 100), dtype=float32) is not from the passed-in graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4c06fb9e0696>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-aa9cc788c26e>\u001b[0m in \u001b[0;36mgenerator\u001b[1;34m(z, reuse)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gen'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                 _reuse=reuse)\n\u001b[1;32m--> 215\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \"\"\"\n\u001b[1;32m--> 503\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\VisualStudio-Lib-Tools\\Anaconda3_64\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    428\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input graph and Layer graph are not the same: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m     with vs.variable_scope(self._scope,\n",
      "\u001b[1;31mValueError\u001b[0m: Input graph and Layer graph are not the same: Tensor(\"Placeholder_3:0\", shape=(?, 100), dtype=float32) is not from the passed-in graph."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diskriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verlustfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.9)) \n",
    "tf.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimierer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ein Sample pro Epoche speichern\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall eine Epoche ist ein ganzer Lauf durch die Trainingsdaten\n",
    "    for e in range(epochs):\n",
    "        # // zeigt die klassische Einteilung\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Batch von Bildern erfassen\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Bilder holen, umgestalten und skalieren, um sie an D zu übergeben.\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (zufällige latente Rauschdaten für den Generator)\n",
    "            # -1 bis 1 wegen der tanh Aktivierung\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Optimierer laufen lassen, keine Notwendigkeit die Ausgaben zu speichern, wir werden sie nicht verwenden.\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Gerade bei Epoche {} von {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Ausschnitt aus dem Generator während des Trainings zur anschließenden Betrachtung\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "#         saver.save(sess, './models/500_epoch_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/500_epoch_model.ckpt')\n",
    "    \n",
    "    for x in range(5):\n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples[0].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

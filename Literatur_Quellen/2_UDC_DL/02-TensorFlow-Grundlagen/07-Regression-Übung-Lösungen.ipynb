{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>© Datamics</em>\n",
    "# Regression Übung - Lösungen\n",
    "\n",
    "## Kalifornische Wohnungsdaten\n",
    "\n",
    "Dieser Datensatz enthält Informationen über alle Blockgruppen in Kalifornien aus der Volkszählung von 1990.\n",
    "\n",
    "In dieser Stichprobe umfasst eine Blockgruppe durchschnittlich 1425,5 Personen, die in einem geografisch kompakten Gebiet leben. \n",
    "\n",
    "Die Aufgabe besteht darin, den mittleren Hauswert jedes Blocks aus den Werten der übrigen Variablen zu nähern. \n",
    "http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Die Features:\n",
    "\n",
    "* housingMedianAge: fortlaufend bzw. kontinuierlich (en. continuous).\n",
    "* totalRooms: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* totalBedrooms: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* population: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* households: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* medianIncome: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* medianHouseValue: fortlaufend bzw. kontinuierlich (en. continuous). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Datensatz\n",
    "Normalerweise würde ich an dieser Stelle das Gesammte Feuerwerk der [EDA](https://github.com/JHC90/Basic-DataScience-Skills/wiki/EDA_Landingpage) abfeuern. Dieser Datensaetz ist aber soweit präpariert, sodass der eigentliche Zweck . Somit kann an dieser Stelle die EDA übersprungen werden. \n",
    "\n",
    "Hier noch der Link zu der [den Python-Modulen](https://github.com/JHC90/PrivatePythonCheats/tree/master/Packete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importiere die `cal_housing.csv` Datei mit Pandas. Unterteile den Datensatz dann in ein Trainings- (70%) und Testdatensatz (30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da hier die Standardabweichung recht hoch ist, werden die Daten noch im nächsten schritt normalisiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side-Info SK-Learn**<br>\n",
    "für die folgenden Schritte aus Datensplit & Skalierung (auch Imputation, das braucht es nur hier nicht, da die Daten sauber geliefert werden)checke meine [SK-Learn-notebook](https://github.com/JHC90/PrivatePythonCheats/blob/master/Packete/Packet_ML_SK-Learn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.drop('medianHouseValue',axis=1), \n",
    "                                                    housing['medianHouseValue'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Orginal-implementierung des Notebooks, meine oben ist besser\n",
    "x_data = housing.drop(['medianHouseValue'],axis=1)\n",
    "y_val = housing['medianHouseValue']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skaliere die Feature Daten\n",
    "\n",
    "** Verwende `sklearn.preprocessing`, um einen MinMaxScaler für die Feature Daten zu erstellen. Passe diesen Skalierer nur auf die Trainingsdaten an. Als nächstes verwenden wir `X_test` und `X_train`, um sie umzuwandeln. Danach verwenden wir `X_test` und `X_train` zusammen mit `pd.Dataframe`, um wieder zwei Datenframes der Skalierten Daten herzustellen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>2.5663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>32.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>35.0</td>\n",
       "      <td>994.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3.5865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.8304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>4.4531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "6761              19.0      2742.0          756.0      1396.0       703.0   \n",
       "3010              32.0       444.0          102.0       242.0        87.0   \n",
       "7812              35.0       994.0          203.0       602.0       185.0   \n",
       "8480              35.0      1281.0          219.0       710.0       184.0   \n",
       "1051              16.0      1257.0          231.0       559.0       213.0   \n",
       "\n",
       "      medianIncome  \n",
       "6761        2.5663  \n",
       "3010        1.1528  \n",
       "7812        3.5865  \n",
       "8480        4.8304  \n",
       "1051        4.4531  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index) # Überschreieb altes mit neuem DF\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index) # Überschreieb altes mit neuem DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die X-Daten (Train & Test) sind nun skaliert. Auf diesen Skalierten Daten werden dann die Modelle trainiert. y(train und test) sind nicht skaliert => Ergo müssen die Ergebnisse zuletzt nicht reskaliert werden.   \n",
    "\n",
    "Durch die Skalierung werden alle werte in den Bereich zwischen 0 &1 übergeben. Das teste ich mit der Head-Fct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>0.048841</td>\n",
       "      <td>0.353133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>0.020795</td>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.770182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.032326</td>\n",
       "      <td>0.040813</td>\n",
       "      <td>0.041662</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.133626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.043212</td>\n",
       "      <td>0.046089</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.263576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14491</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.088433</td>\n",
       "      <td>0.069367</td>\n",
       "      <td>0.043728</td>\n",
       "      <td>0.072192</td>\n",
       "      <td>0.660046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "16086          0.686275    0.046264       0.045158    0.025873    0.048841   \n",
       "8816           0.705882    0.027417       0.020795    0.012709    0.023187   \n",
       "7175           0.901961    0.032326       0.040813    0.041662    0.042592   \n",
       "16714          0.313725    0.043212       0.046089    0.032840    0.048018   \n",
       "14491          0.411765    0.088433       0.069367    0.043728    0.072192   \n",
       "\n",
       "       medianIncome  \n",
       "16086      0.353133  \n",
       "8816       0.770182  \n",
       "7175       0.133626  \n",
       "16714      0.263576  \n",
       "14491      0.660046  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Spalten erstellen\n",
    "\n",
    "** Erstelle die benötigten `tf.feature_column` Objekte für die Schätzer. Wir benutzen sie als kontinuierliche `numeric_columns`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() # es soll sich wie TF-1.6.0 verhalten. Dazu ist die Syntax adaptiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somit sind die Feature-Cols\n",
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle die Input-Funktion for das Estimator Objekt. (Spiele dabei mit den Werten der batch_size und num_epochs)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle das Schätz Modell. Verwende `DBBRegressor`. Spiele auch mit den versteckten Einheiten ein wenig rum**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpg2a6xkoo\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\181083~1\\\\AppData\\\\Local\\\\Temp\\\\tmpg2a6xkoo', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002101A953308>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# In diesem Fall 3 Layer mit jeweils 6 Neuronen, sprich hier wird das Model eigenlicht nur erstellt\n",
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainiere das Modell für ca. 1000 Schritte.**\n",
    "\n",
    "*Hinweis: Später kannst du es dann weiter trainieren, um mögliche Verbesserungen zu sehen.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000210210B0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000210210B0748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000210210B0748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000210210B0748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000210210BFA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000210210BFA48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000210210BFA48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000210210BFA48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210BF648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210BF648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210BF648>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210BF648>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210DD748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210DD748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210DD748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210DD748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EA688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EA688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EA688>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EA688>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EAB88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EAB88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EAB88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000210210EAB88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpg2a6xkoo\\model.ckpt.\n",
      "INFO:tensorflow:loss = 526166620000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 342.468\n",
      "INFO:tensorflow:loss = 504371300000.0, step = 101 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.607\n",
      "INFO:tensorflow:loss = 790102500000.0, step = 201 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 410.322\n",
      "INFO:tensorflow:loss = 306557120000.0, step = 301 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.037\n",
      "INFO:tensorflow:loss = 431918000000.0, step = 401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.435\n",
      "INFO:tensorflow:loss = 228247570000.0, step = 501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.855\n",
      "INFO:tensorflow:loss = 1120850500000.0, step = 601 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.139\n",
      "INFO:tensorflow:loss = 237594130000.0, step = 701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.829\n",
      "INFO:tensorflow:loss = 295246730000.0, step = 801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.12\n",
      "INFO:tensorflow:loss = 624807200000.0, step = 901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.625\n",
      "INFO:tensorflow:loss = 230854260000.0, step = 1001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.621\n",
      "INFO:tensorflow:loss = 210982040000.0, step = 1101 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.138\n",
      "INFO:tensorflow:loss = 177355460000.0, step = 1201 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.946\n",
      "INFO:tensorflow:loss = 420789620000.0, step = 1301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.737\n",
      "INFO:tensorflow:loss = 265471670000.0, step = 1401 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.56\n",
      "INFO:tensorflow:loss = 252619700000.0, step = 1501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.749\n",
      "INFO:tensorflow:loss = 144542940000.0, step = 1601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.196\n",
      "INFO:tensorflow:loss = 376444030000.0, step = 1701 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.537\n",
      "INFO:tensorflow:loss = 158340530000.0, step = 1801 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.298\n",
      "INFO:tensorflow:loss = 253861640000.0, step = 1901 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.516\n",
      "INFO:tensorflow:loss = 82721700000.0, step = 2001 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.583\n",
      "INFO:tensorflow:loss = 105640395000.0, step = 2101 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.42\n",
      "INFO:tensorflow:loss = 185758120000.0, step = 2201 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.337\n",
      "INFO:tensorflow:loss = 121475910000.0, step = 2301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.357\n",
      "INFO:tensorflow:loss = 63822307000.0, step = 2401 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.533\n",
      "INFO:tensorflow:loss = 122442220000.0, step = 2501 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.034\n",
      "INFO:tensorflow:loss = 81956766000.0, step = 2601 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.03\n",
      "INFO:tensorflow:loss = 41435075000.0, step = 2701 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.526\n",
      "INFO:tensorflow:loss = 57084590000.0, step = 2801 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.561\n",
      "INFO:tensorflow:loss = 44548120000.0, step = 2901 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.169\n",
      "INFO:tensorflow:loss = 73814000000.0, step = 3001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.104\n",
      "INFO:tensorflow:loss = 105230490000.0, step = 3101 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.006\n",
      "INFO:tensorflow:loss = 81711170000.0, step = 3201 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.96\n",
      "INFO:tensorflow:loss = 130928480000.0, step = 3301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.526\n",
      "INFO:tensorflow:loss = 52494815000.0, step = 3401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.228\n",
      "INFO:tensorflow:loss = 107574840000.0, step = 3501 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.224\n",
      "INFO:tensorflow:loss = 90452200000.0, step = 3601 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.433\n",
      "INFO:tensorflow:loss = 82891596000.0, step = 3701 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.637\n",
      "INFO:tensorflow:loss = 109225296000.0, step = 3801 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.315\n",
      "INFO:tensorflow:loss = 54057116000.0, step = 3901 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.963\n",
      "INFO:tensorflow:loss = 62248817000.0, step = 4001 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.621\n",
      "INFO:tensorflow:loss = 146431660000.0, step = 4101 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.41\n",
      "INFO:tensorflow:loss = 135975230000.0, step = 4201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.404\n",
      "INFO:tensorflow:loss = 73370510000.0, step = 4301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.449\n",
      "INFO:tensorflow:loss = 101086265000.0, step = 4401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.713\n",
      "INFO:tensorflow:loss = 273453150000.0, step = 4501 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.526\n",
      "INFO:tensorflow:loss = 83556475000.0, step = 4601 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.783\n",
      "INFO:tensorflow:loss = 170168270000.0, step = 4701 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.038\n",
      "INFO:tensorflow:loss = 36762534000.0, step = 4801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.666\n",
      "INFO:tensorflow:loss = 169742960000.0, step = 4901 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.478\n",
      "INFO:tensorflow:loss = 181399400000.0, step = 5001 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.445\n",
      "INFO:tensorflow:loss = 138722690000.0, step = 5101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.428\n",
      "INFO:tensorflow:loss = 48438230000.0, step = 5201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.939\n",
      "INFO:tensorflow:loss = 98533710000.0, step = 5301 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.227\n",
      "INFO:tensorflow:loss = 45762793000.0, step = 5401 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.837\n",
      "INFO:tensorflow:loss = 77792110000.0, step = 5501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.035\n",
      "INFO:tensorflow:loss = 54362382000.0, step = 5601 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.116\n",
      "INFO:tensorflow:loss = 55769014000.0, step = 5701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.712\n",
      "INFO:tensorflow:loss = 101748064000.0, step = 5801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.965\n",
      "INFO:tensorflow:loss = 246079680000.0, step = 5901 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.115\n",
      "INFO:tensorflow:loss = 134909420000.0, step = 6001 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.679\n",
      "INFO:tensorflow:loss = 114441410000.0, step = 6101 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.598\n",
      "INFO:tensorflow:loss = 28244785000.0, step = 6201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.621\n",
      "INFO:tensorflow:loss = 194604560000.0, step = 6301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.117\n",
      "INFO:tensorflow:loss = 22324201000.0, step = 6401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.829\n",
      "INFO:tensorflow:loss = 93222530000.0, step = 6501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.829\n",
      "INFO:tensorflow:loss = 109529630000.0, step = 6601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.784\n",
      "INFO:tensorflow:loss = 41705808000.0, step = 6701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.425\n",
      "INFO:tensorflow:loss = 131853664000.0, step = 6801 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.143\n",
      "INFO:tensorflow:loss = 118152820000.0, step = 6901 (0.227 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 460.913\n",
      "INFO:tensorflow:loss = 57926620000.0, step = 7001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.716\n",
      "INFO:tensorflow:loss = 59657142000.0, step = 7101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.54\n",
      "INFO:tensorflow:loss = 44094050000.0, step = 7201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.617\n",
      "INFO:tensorflow:loss = 58465950000.0, step = 7301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.969\n",
      "INFO:tensorflow:loss = 58901670000.0, step = 7401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.472\n",
      "INFO:tensorflow:loss = 93347760000.0, step = 7501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.621\n",
      "INFO:tensorflow:loss = 164048850000.0, step = 7601 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.62\n",
      "INFO:tensorflow:loss = 179834550000.0, step = 7701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.694\n",
      "INFO:tensorflow:loss = 101271390000.0, step = 7801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.966\n",
      "INFO:tensorflow:loss = 48186300000.0, step = 7901 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.83\n",
      "INFO:tensorflow:loss = 128285380000.0, step = 8001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.828\n",
      "INFO:tensorflow:loss = 139813910000.0, step = 8101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.033\n",
      "INFO:tensorflow:loss = 128767566000.0, step = 8201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.871\n",
      "INFO:tensorflow:loss = 50175275000.0, step = 8301 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.003\n",
      "INFO:tensorflow:loss = 69813050000.0, step = 8401 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.319\n",
      "INFO:tensorflow:loss = 135366930000.0, step = 8501 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.222\n",
      "INFO:tensorflow:loss = 84318640000.0, step = 8601 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.29\n",
      "INFO:tensorflow:loss = 85458560000.0, step = 8701 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.651\n",
      "INFO:tensorflow:loss = 104698800000.0, step = 8801 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.633\n",
      "INFO:tensorflow:loss = 87422304000.0, step = 8901 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.703\n",
      "INFO:tensorflow:loss = 67808160000.0, step = 9001 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.784\n",
      "INFO:tensorflow:loss = 76564660000.0, step = 9101 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.426\n",
      "INFO:tensorflow:loss = 65916540000.0, step = 9201 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.616\n",
      "INFO:tensorflow:loss = 65660320000.0, step = 9301 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.477\n",
      "INFO:tensorflow:loss = 42055643000.0, step = 9401 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.124\n",
      "INFO:tensorflow:loss = 134109000000.0, step = 9501 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.488\n",
      "INFO:tensorflow:loss = 153862720000.0, step = 9601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.429\n",
      "INFO:tensorflow:loss = 46531820000.0, step = 9701 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.287\n",
      "INFO:tensorflow:loss = 66034168000.0, step = 9801 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.724\n",
      "INFO:tensorflow:loss = 73478810000.0, step = 9901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.476\n",
      "INFO:tensorflow:loss = 129358990000.0, step = 10001 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.706\n",
      "INFO:tensorflow:loss = 77766480000.0, step = 10101 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.717\n",
      "INFO:tensorflow:loss = 116099250000.0, step = 10201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.543\n",
      "INFO:tensorflow:loss = 253823960000.0, step = 10301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.546\n",
      "INFO:tensorflow:loss = 104489930000.0, step = 10401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.428\n",
      "INFO:tensorflow:loss = 155023280000.0, step = 10501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.115\n",
      "INFO:tensorflow:loss = 194134790000.0, step = 10601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.435\n",
      "INFO:tensorflow:loss = 213178520000.0, step = 10701 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.709\n",
      "INFO:tensorflow:loss = 93920150000.0, step = 10801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.208\n",
      "INFO:tensorflow:loss = 83617300000.0, step = 10901 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.548\n",
      "INFO:tensorflow:loss = 93931430000.0, step = 11001 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.487\n",
      "INFO:tensorflow:loss = 111528804000.0, step = 11101 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.833\n",
      "INFO:tensorflow:loss = 155214710000.0, step = 11201 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.962\n",
      "INFO:tensorflow:loss = 30670700000.0, step = 11301 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.829\n",
      "INFO:tensorflow:loss = 118140560000.0, step = 11401 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.621\n",
      "INFO:tensorflow:loss = 149947060000.0, step = 11501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.83\n",
      "INFO:tensorflow:loss = 264315470000.0, step = 11601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.957\n",
      "INFO:tensorflow:loss = 88185500000.0, step = 11701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.718\n",
      "INFO:tensorflow:loss = 103328290000.0, step = 11801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.487\n",
      "INFO:tensorflow:loss = 169741430000.0, step = 11901 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.716\n",
      "INFO:tensorflow:loss = 49895633000.0, step = 12001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.826\n",
      "INFO:tensorflow:loss = 90844860000.0, step = 12101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.621\n",
      "INFO:tensorflow:loss = 138217820000.0, step = 12201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.712\n",
      "INFO:tensorflow:loss = 93673970000.0, step = 12301 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.49\n",
      "INFO:tensorflow:loss = 119590080000.0, step = 12401 (0.213 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12402 vs previous value: 12402. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 454.545\n",
      "INFO:tensorflow:loss = 54311145000.0, step = 12501 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.433\n",
      "INFO:tensorflow:loss = 118967860000.0, step = 12601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.928\n",
      "INFO:tensorflow:loss = 106402240000.0, step = 12701 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.443\n",
      "INFO:tensorflow:loss = 186695800000.0, step = 12801 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.547\n",
      "INFO:tensorflow:loss = 38342060000.0, step = 12901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.431\n",
      "INFO:tensorflow:loss = 106485870000.0, step = 13001 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.187\n",
      "INFO:tensorflow:loss = 136955900000.0, step = 13101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.479\n",
      "INFO:tensorflow:loss = 167959970000.0, step = 13201 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.294\n",
      "INFO:tensorflow:loss = 89962140000.0, step = 13301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.596\n",
      "INFO:tensorflow:loss = 145703060000.0, step = 13401 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.626\n",
      "INFO:tensorflow:loss = 107168840000.0, step = 13501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.491\n",
      "INFO:tensorflow:loss = 64996057000.0, step = 13601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.958\n",
      "INFO:tensorflow:loss = 70141460000.0, step = 13701 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.717\n",
      "INFO:tensorflow:loss = 39660160000.0, step = 13801 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.624\n",
      "INFO:tensorflow:loss = 87705340000.0, step = 13901 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.484\n",
      "INFO:tensorflow:loss = 142419920000.0, step = 14001 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.433\n",
      "INFO:tensorflow:loss = 65454530000.0, step = 14101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.593\n",
      "INFO:tensorflow:loss = 133542580000.0, step = 14201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.492\n",
      "INFO:tensorflow:loss = 79654530000.0, step = 14301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.483\n",
      "INFO:tensorflow:loss = 127110350000.0, step = 14401 (0.220 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 14438 vs previous value: 14438. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 440.528\n",
      "INFO:tensorflow:loss = 147876120000.0, step = 14501 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.83\n",
      "INFO:tensorflow:loss = 122410934000.0, step = 14601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.29\n",
      "INFO:tensorflow:loss = 172184030000.0, step = 14701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.111\n",
      "INFO:tensorflow:loss = 37233580000.0, step = 14801 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.483\n",
      "INFO:tensorflow:loss = 42603650000.0, step = 14901 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.618\n",
      "INFO:tensorflow:loss = 132325835000.0, step = 15001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.123\n",
      "INFO:tensorflow:loss = 129518300000.0, step = 15101 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.003\n",
      "INFO:tensorflow:loss = 138136300000.0, step = 15201 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.319\n",
      "INFO:tensorflow:loss = 125617420000.0, step = 15301 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.98\n",
      "INFO:tensorflow:loss = 101622320000.0, step = 15401 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.436\n",
      "INFO:tensorflow:loss = 65458696000.0, step = 15501 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.824\n",
      "INFO:tensorflow:loss = 146230100000.0, step = 15601 (0.290 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 15647 vs previous value: 15647. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 340.141\n",
      "INFO:tensorflow:loss = 89225180000.0, step = 15701 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.633\n",
      "INFO:tensorflow:loss = 132606640000.0, step = 15801 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.871\n",
      "INFO:tensorflow:loss = 105693950000.0, step = 15901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.01\n",
      "INFO:tensorflow:loss = 82748380000.0, step = 16001 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.225\n",
      "INFO:tensorflow:loss = 55318580000.0, step = 16101 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.596\n",
      "INFO:tensorflow:loss = 159363870000.0, step = 16201 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.453\n",
      "INFO:tensorflow:loss = 149234250000.0, step = 16301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.544\n",
      "INFO:tensorflow:loss = 59935973000.0, step = 16401 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.441\n",
      "INFO:tensorflow:loss = 57209065000.0, step = 16501 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.901\n",
      "INFO:tensorflow:loss = 80116250000.0, step = 16601 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.601\n",
      "INFO:tensorflow:loss = 120633020000.0, step = 16701 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.791\n",
      "INFO:tensorflow:loss = 80877550000.0, step = 16801 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.594\n",
      "INFO:tensorflow:loss = 152134980000.0, step = 16901 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.717\n",
      "INFO:tensorflow:loss = 116721025000.0, step = 17001 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.681\n",
      "INFO:tensorflow:loss = 57070453000.0, step = 17101 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.786\n",
      "INFO:tensorflow:loss = 51430396000.0, step = 17201 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.429\n",
      "INFO:tensorflow:loss = 182163830000.0, step = 17301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.528\n",
      "INFO:tensorflow:loss = 80417790000.0, step = 17401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.729\n",
      "INFO:tensorflow:loss = 77578310000.0, step = 17501 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.489\n",
      "INFO:tensorflow:loss = 77713720000.0, step = 17601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.714\n",
      "INFO:tensorflow:loss = 86646490000.0, step = 17701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.453\n",
      "INFO:tensorflow:loss = 57482592000.0, step = 17801 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.533\n",
      "INFO:tensorflow:loss = 64938885000.0, step = 17901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.679\n",
      "INFO:tensorflow:loss = 30095065000.0, step = 18001 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.431\n",
      "INFO:tensorflow:loss = 66406990000.0, step = 18101 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.897\n",
      "INFO:tensorflow:loss = 82531970000.0, step = 18201 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.532\n",
      "INFO:tensorflow:loss = 79281540000.0, step = 18301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.002\n",
      "INFO:tensorflow:loss = 155536720000.0, step = 18401 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.687\n",
      "INFO:tensorflow:loss = 76203370000.0, step = 18501 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.484\n",
      "INFO:tensorflow:loss = 65819160000.0, step = 18601 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.941\n",
      "INFO:tensorflow:loss = 156556750000.0, step = 18701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.68\n",
      "INFO:tensorflow:loss = 46323100000.0, step = 18801 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.227\n",
      "INFO:tensorflow:loss = 78647330000.0, step = 18901 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.157\n",
      "INFO:tensorflow:loss = 141501660000.0, step = 19001 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.94\n",
      "INFO:tensorflow:loss = 17696571000.0, step = 19101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.448\n",
      "INFO:tensorflow:loss = 97504690000.0, step = 19201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.783\n",
      "INFO:tensorflow:loss = 59480633000.0, step = 19301 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.9\n",
      "INFO:tensorflow:loss = 48464930000.0, step = 19401 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.596\n",
      "INFO:tensorflow:loss = 98058200000.0, step = 19501 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.405\n",
      "INFO:tensorflow:loss = 39055897000.0, step = 19601 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.946\n",
      "INFO:tensorflow:loss = 82849890000.0, step = 19701 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.544\n",
      "INFO:tensorflow:loss = 82736590000.0, step = 19801 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.571\n",
      "INFO:tensorflow:loss = 217675300000.0, step = 19901 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.983\n",
      "INFO:tensorflow:loss = 175030900000.0, step = 20001 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.934\n",
      "INFO:tensorflow:loss = 110821196000.0, step = 20101 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.168\n",
      "INFO:tensorflow:loss = 88766710000.0, step = 20201 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.531\n",
      "INFO:tensorflow:loss = 93382210000.0, step = 20301 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.523\n",
      "INFO:tensorflow:loss = 47690383000.0, step = 20401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.082\n",
      "INFO:tensorflow:loss = 75398660000.0, step = 20501 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.489\n",
      "INFO:tensorflow:loss = 66251735000.0, step = 20601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.221\n",
      "INFO:tensorflow:loss = 140953320000.0, step = 20701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.428\n",
      "INFO:tensorflow:loss = 89762270000.0, step = 20801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.432\n",
      "INFO:tensorflow:loss = 44913558000.0, step = 20901 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.531\n",
      "INFO:tensorflow:loss = 38367050000.0, step = 21001 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.429\n",
      "INFO:tensorflow:loss = 13226883000.0, step = 21101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.525\n",
      "INFO:tensorflow:loss = 109223140000.0, step = 21201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.448\n",
      "INFO:tensorflow:loss = 48945545000.0, step = 21301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.426\n",
      "INFO:tensorflow:loss = 91701354000.0, step = 21401 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.606\n",
      "INFO:tensorflow:loss = 56723575000.0, step = 21501 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.17\n",
      "INFO:tensorflow:loss = 179796410000.0, step = 21601 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.549\n",
      "INFO:tensorflow:loss = 82254060000.0, step = 21701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.432\n",
      "INFO:tensorflow:loss = 70234440000.0, step = 21801 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.135\n",
      "INFO:tensorflow:loss = 103275440000.0, step = 21901 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.541\n",
      "INFO:tensorflow:loss = 65020576000.0, step = 22001 (0.312 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 348.433\n",
      "INFO:tensorflow:loss = 149379840000.0, step = 22101 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.489\n",
      "INFO:tensorflow:loss = 132669420000.0, step = 22201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.847\n",
      "INFO:tensorflow:loss = 88950415000.0, step = 22301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.834\n",
      "INFO:tensorflow:loss = 69627940000.0, step = 22401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.872\n",
      "INFO:tensorflow:loss = 58564764000.0, step = 22501 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.613\n",
      "INFO:tensorflow:loss = 188030940000.0, step = 22601 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.547\n",
      "INFO:tensorflow:loss = 108321760000.0, step = 22701 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.596\n",
      "INFO:tensorflow:loss = 51286225000.0, step = 22801 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.394\n",
      "INFO:tensorflow:loss = 109638205000.0, step = 22901 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.453\n",
      "INFO:tensorflow:loss = 116276314000.0, step = 23001 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.45\n",
      "INFO:tensorflow:loss = 194736300000.0, step = 23101 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.449\n",
      "INFO:tensorflow:loss = 59568260000.0, step = 23201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.779\n",
      "INFO:tensorflow:loss = 79424350000.0, step = 23301 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.551\n",
      "INFO:tensorflow:loss = 50055390000.0, step = 23401 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.477\n",
      "INFO:tensorflow:loss = 58603200000.0, step = 23501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.369\n",
      "INFO:tensorflow:loss = 46056215000.0, step = 23601 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.031\n",
      "INFO:tensorflow:loss = 163345220000.0, step = 23701 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.434\n",
      "INFO:tensorflow:loss = 73924270000.0, step = 23801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.431\n",
      "INFO:tensorflow:loss = 103810380000.0, step = 23901 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.034\n",
      "INFO:tensorflow:loss = 195668620000.0, step = 24001 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.565\n",
      "INFO:tensorflow:loss = 149560870000.0, step = 24101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.443\n",
      "INFO:tensorflow:loss = 82648990000.0, step = 24201 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.49\n",
      "INFO:tensorflow:loss = 61792436000.0, step = 24301 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.449\n",
      "INFO:tensorflow:loss = 129119960000.0, step = 24401 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.592\n",
      "INFO:tensorflow:loss = 33126924000.0, step = 24501 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.859\n",
      "INFO:tensorflow:loss = 89160830000.0, step = 24601 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.479\n",
      "INFO:tensorflow:loss = 77442650000.0, step = 24701 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.486\n",
      "INFO:tensorflow:loss = 105459550000.0, step = 24801 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.797\n",
      "INFO:tensorflow:loss = 65071090000.0, step = 24901 (0.231 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpg2a6xkoo\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 46115910000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x2101a957208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle eine Vorhersage-Eingabefunktion und verwende dann die Methode `.predict` aus Deinem Schätzmodell, um eine Liste oder Vorhersagen für deine Testdaten zu erstellen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier entstehen die Predictions\n",
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x0000021021B25988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x0000021021B25988>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x0000021021B25988>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x0000021021B25988>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x0000021022F72DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x0000021022F72DC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x0000021022F72DC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x0000021022F72DC8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F80CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F80CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F80CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F80CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F809C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F809C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F809C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F809C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F847C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F847C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F847C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F847C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F84CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F84CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F84CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000021022F84CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\1810837475\\.conda\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpg2a6xkoo\\model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Berechne die RMSE. Dies kannst du manuell machen oder wahlweise mit: [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier erstellen wir eine Liste aller Predictions für d\n",
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98966.796734742"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check der y_tset gegen die preds mit dem RMSE\n",
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Fehler ist schon verdammt hoch, diese NB diente lediglich der Vorgehensweise mit TF darzustellen. Eine weitere Herangehensweise wäre nun die Anzahl der Layer & Neuronen zu ändern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gut gemacht!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

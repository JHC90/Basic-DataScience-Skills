{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://datamics.com/de/courses/\"><img src=../DATA/bg_datamics_top.png></a>\n",
    "\n",
    "<em text-align:center>© Datamics</em>\n",
    "# Regression Übung - Aufgaben\n",
    "\n",
    "\n",
    "## Kalifornische Wohnungsdaten\n",
    "\n",
    "Dieser Datensatz enthält Informationen über alle Blockgruppen in Kalifornien aus der Volkszählung von 1990.\n",
    "\n",
    "In dieser Stichprobe umfasst eine Blockgruppe durchschnittlich 1425,5 Personen, die in einem geografisch kompakten Gebiet leben. \n",
    "\n",
    "Die Aufgabe besteht darin, den mittleren Hauswert jedes Blocks aus den Werten der übrigen Variablen zu nähern. \n",
    "http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Die Features:\n",
    "\n",
    "* housingMedianAge: fortlaufend bzw. kontinuierlich (en. continuous).\n",
    "* totalRooms: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* totalBedrooms: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* population: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* households: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* medianIncome: fortlaufend bzw. kontinuierlich (en. continuous). \n",
    "* medianHouseValue: fortlaufend bzw. kontinuierlich (en. continuous). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibs\n",
    "# Bibliotheken \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Datensatz\n",
    "hier meine erste [Checkliste](https://github.com/JHC90/Basic-DataScience-Skills/wiki/EDA_Landingpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importiere die `cal_housing.csv` Datei mit Pandas. Unterteile den Datensatz dann in ein Trainings- (70%) und Testdatensatz (30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cal_housing_clean.csv',delimiter=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "20635              25.0      1665.0          374.0       845.0       330.0   \n",
       "20636              18.0       697.0          150.0       356.0       114.0   \n",
       "20637              17.0      2254.0          485.0      1007.0       433.0   \n",
       "20638              18.0      1860.0          409.0       741.0       349.0   \n",
       "20639              16.0      2785.0          616.0      1387.0       530.0   \n",
       "\n",
       "       medianIncome  medianHouseValue  \n",
       "20635        1.5603           78100.0  \n",
       "20636        2.5568           77100.0  \n",
       "20637        1.7000           92300.0  \n",
       "20638        1.8672           84700.0  \n",
       "20639        2.3886           89400.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna()\n",
    "df.isna().any()\n",
    "df.isna().any().any()\n",
    "# msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   housingMedianAge  20640 non-null  float64\n",
      " 1   totalRooms        20640 non-null  float64\n",
      " 2   totalBedrooms     20640 non-null  float64\n",
      " 3   population        20640 non-null  float64\n",
      " 4   households        20640 non-null  float64\n",
      " 5   medianIncome      20640 non-null  float64\n",
      " 6   medianHouseValue  20640 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge    totalRooms  totalBedrooms    population  \\\n",
       "count      20640.000000  20640.000000   20640.000000  20640.000000   \n",
       "mean          28.639486   2635.763081     537.898014   1425.476744   \n",
       "std           12.585558   2181.615252     421.247906   1132.462122   \n",
       "min            1.000000      2.000000       1.000000      3.000000   \n",
       "25%           18.000000   1447.750000     295.000000    787.000000   \n",
       "50%           29.000000   2127.000000     435.000000   1166.000000   \n",
       "75%           37.000000   3148.000000     647.000000   1725.000000   \n",
       "max           52.000000  39320.000000    6445.000000  35682.000000   \n",
       "\n",
       "         households  medianIncome  medianHouseValue  \n",
       "count  20640.000000  20640.000000      20640.000000  \n",
       "mean     499.539680      3.870671     206855.816909  \n",
       "std      382.329753      1.899822     115395.615874  \n",
       "min        1.000000      0.499900      14999.000000  \n",
       "25%      280.000000      2.563400     119600.000000  \n",
       "50%      409.000000      3.534800     179700.000000  \n",
       "75%      605.000000      4.743250     264725.000000  \n",
       "max     6082.000000     15.000100     500001.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK-learn\n",
    "für die folgenden Schritte aus Datensplit & Skalierung (auch Imputation, das braucht es nur hier nicht, da die Daten sauber geliefert werden)checke meine [SK-Learn-notebook](https://github.com/JHC90/PrivatePythonCheats/blob/master/Packete/Packet_ML_SK-Learn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test-Split\n",
    "Check die Sklearn-Mitschrift, hier kann ich einen Horizontalen & Vertiaklen Cut in einem 1-Zeiler erledigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('medianHouseValue',axis=1), \n",
    "                                                    df['medianHouseValue'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skaliere die Feature Daten\n",
    "\n",
    "** Verwende `sklearn.preprocessing`, um einen MinMaxScaler für die Feature Daten zu erstellen. Passe diesen Skalierer nur auf die Trainingsdaten an. Als nächstes verwenden wir `X_test` und `X_train`, um sie umzuwandeln. Danach verwenden wir `X_test` und `X_train` zusammen mit `pd.Dataframe`, um wieder zwei Datenframes der Skalierten Daten herzustellen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Spalten erstellen\n",
    "\n",
    "** Erstelle die benötigten `tf.feature_column` Objekte für die Schätzer. Wir benutzen sie als kontinuierliche `numeric_columns`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')\n",
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle die Input-Funktion for das Estimator Objekt. (Spiele dabei mit den Werten der batch_size und num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dient für das Training des estimators => daher den Shuffle auf True = man bekommt unterschiedlcihe DAten eingelesen\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)\n",
    "train_input_func = tf.estimator.inputs.numpy_input_fn({'x':X_train},y_train,batch_size=4,num_epochs=1000,shuffle=False)\n",
    "eval_input_func = tf.estimator.inputs.numpy_input_fn({'x':X_test},y_test,batch_size=4,num_epochs=1000,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle das Schätz Modell. Verwende `DBBRegressor`. Spiele auch mit den versteckten Einheiten ein wenig rum**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpxyg8jez1\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\181083~1\\\\AppData\\\\Local\\\\Temp\\\\tmpxyg8jez1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000198DDAD1548>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainiere das Modell für ca. 1000 Schritte.**\n",
    "\n",
    "*Hinweis: Später kannst du es dann weiter trainieren, um mögliche Verbesserungen zu sehen.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DE46C7C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DE46C7C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DE46C7C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DE46C7C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDDE6B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDDE6B08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDDE6B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDDE6B08>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7D08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF7508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF8A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF8A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF8A88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DDDF8A88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpxyg8jez1\\model.ckpt-26000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpxyg8jez1\\model.ckpt.\n",
      "INFO:tensorflow:loss = 50556133000.0, step = 26001\n",
      "INFO:tensorflow:global_step/sec: 368.479\n",
      "INFO:tensorflow:loss = 82327080000.0, step = 26101 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.422\n",
      "INFO:tensorflow:loss = 25373950000.0, step = 26201 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.267\n",
      "INFO:tensorflow:loss = 117804270000.0, step = 26301 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.846\n",
      "INFO:tensorflow:loss = 49593350000.0, step = 26401 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.703\n",
      "INFO:tensorflow:loss = 104978874000.0, step = 26501 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.357\n",
      "INFO:tensorflow:loss = 122619126000.0, step = 26601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.917\n",
      "INFO:tensorflow:loss = 42953605000.0, step = 26701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.561\n",
      "INFO:tensorflow:loss = 55941310000.0, step = 26801 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.018\n",
      "INFO:tensorflow:loss = 39195615000.0, step = 26901 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.992\n",
      "INFO:tensorflow:loss = 56980304000.0, step = 27001 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.188\n",
      "INFO:tensorflow:loss = 42381922000.0, step = 27101 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.475\n",
      "INFO:tensorflow:loss = 73204790000.0, step = 27201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.438\n",
      "INFO:tensorflow:loss = 100142560000.0, step = 27301 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 52749783000.0, step = 27401 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.852\n",
      "INFO:tensorflow:loss = 50220528000.0, step = 27501 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.938\n",
      "INFO:tensorflow:loss = 69499445000.0, step = 27601 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.708\n",
      "INFO:tensorflow:loss = 32185672000.0, step = 27701 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.07\n",
      "INFO:tensorflow:loss = 99793175000.0, step = 27801 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.415\n",
      "INFO:tensorflow:loss = 40449170000.0, step = 27901 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.099\n",
      "INFO:tensorflow:loss = 137193290000.0, step = 28001 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.812\n",
      "INFO:tensorflow:loss = 29607199000.0, step = 28101 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.735\n",
      "INFO:tensorflow:loss = 34966950000.0, step = 28201 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.427\n",
      "INFO:tensorflow:loss = 158192440000.0, step = 28301 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.513\n",
      "INFO:tensorflow:loss = 93693840000.0, step = 28401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.311\n",
      "INFO:tensorflow:loss = 58161267000.0, step = 28501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.612\n",
      "INFO:tensorflow:loss = 67007427000.0, step = 28601 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.46\n",
      "INFO:tensorflow:loss = 47579110000.0, step = 28701 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.817\n",
      "INFO:tensorflow:loss = 61846020000.0, step = 28801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.509\n",
      "INFO:tensorflow:loss = 24795795000.0, step = 28901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.397\n",
      "INFO:tensorflow:loss = 42863927000.0, step = 29001 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.414\n",
      "INFO:tensorflow:loss = 90796570000.0, step = 29101 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.24\n",
      "INFO:tensorflow:loss = 126706280000.0, step = 29201 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.719\n",
      "INFO:tensorflow:loss = 82722095000.0, step = 29301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.87\n",
      "INFO:tensorflow:loss = 42621583000.0, step = 29401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.825\n",
      "INFO:tensorflow:loss = 30828767000.0, step = 29501 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.948\n",
      "INFO:tensorflow:loss = 60320588000.0, step = 29601 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.26\n",
      "INFO:tensorflow:loss = 81437245000.0, step = 29701 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.961\n",
      "INFO:tensorflow:loss = 100839540000.0, step = 29801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.468\n",
      "INFO:tensorflow:loss = 108750590000.0, step = 29901 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.203\n",
      "INFO:tensorflow:loss = 112654350000.0, step = 30001 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.289\n",
      "INFO:tensorflow:loss = 30020594000.0, step = 30101 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.534\n",
      "INFO:tensorflow:loss = 44966728000.0, step = 30201 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.714\n",
      "INFO:tensorflow:loss = 51990570000.0, step = 30301 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.682\n",
      "INFO:tensorflow:loss = 74725810000.0, step = 30401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.193\n",
      "INFO:tensorflow:loss = 82857890000.0, step = 30501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.323\n",
      "INFO:tensorflow:loss = 74917220000.0, step = 30601 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.303\n",
      "INFO:tensorflow:loss = 104275075000.0, step = 30701 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.003\n",
      "INFO:tensorflow:loss = 85477340000.0, step = 30801 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.589\n",
      "INFO:tensorflow:loss = 36625270000.0, step = 30901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.104\n",
      "INFO:tensorflow:loss = 81281170000.0, step = 31001 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.115\n",
      "INFO:tensorflow:loss = 80521180000.0, step = 31101 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.841\n",
      "INFO:tensorflow:loss = 88517360000.0, step = 31201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.641\n",
      "INFO:tensorflow:loss = 76022050000.0, step = 31301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.207\n",
      "INFO:tensorflow:loss = 83265760000.0, step = 31401 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.61\n",
      "INFO:tensorflow:loss = 49968255000.0, step = 31501 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.954\n",
      "INFO:tensorflow:loss = 41833240000.0, step = 31601 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.33\n",
      "INFO:tensorflow:loss = 78225680000.0, step = 31701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.22\n",
      "INFO:tensorflow:loss = 27178465000.0, step = 31801 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.106\n",
      "INFO:tensorflow:loss = 114666140000.0, step = 31901 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.02\n",
      "INFO:tensorflow:loss = 47781863000.0, step = 32001 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.212\n",
      "INFO:tensorflow:loss = 75972960000.0, step = 32101 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.871\n",
      "INFO:tensorflow:loss = 34651873000.0, step = 32201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.972\n",
      "INFO:tensorflow:loss = 51120243000.0, step = 32301 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.577\n",
      "INFO:tensorflow:loss = 44418110000.0, step = 32401 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.318\n",
      "INFO:tensorflow:loss = 40278802000.0, step = 32501 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.505\n",
      "INFO:tensorflow:loss = 58529260000.0, step = 32601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.864\n",
      "INFO:tensorflow:loss = 52179890000.0, step = 32701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.638\n",
      "INFO:tensorflow:loss = 46827295000.0, step = 32801 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.009\n",
      "INFO:tensorflow:loss = 133589320000.0, step = 32901 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.353\n",
      "INFO:tensorflow:loss = 80193600000.0, step = 33001 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.121\n",
      "INFO:tensorflow:loss = 126221560000.0, step = 33101 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.232\n",
      "INFO:tensorflow:loss = 102734480000.0, step = 33201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.593\n",
      "INFO:tensorflow:loss = 135623070000.0, step = 33301 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.18\n",
      "INFO:tensorflow:loss = 39237320000.0, step = 33401 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.826\n",
      "INFO:tensorflow:loss = 63893610000.0, step = 33501 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.574\n",
      "INFO:tensorflow:loss = 54301670000.0, step = 33601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.042\n",
      "INFO:tensorflow:loss = 34317822000.0, step = 33701 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.656\n",
      "INFO:tensorflow:loss = 22556537000.0, step = 33801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.62\n",
      "INFO:tensorflow:loss = 35816260000.0, step = 33901 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.026\n",
      "INFO:tensorflow:loss = 92479240000.0, step = 34001 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.776\n",
      "INFO:tensorflow:loss = 41111640000.0, step = 34101 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.051\n",
      "INFO:tensorflow:loss = 27770090000.0, step = 34201 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.407\n",
      "INFO:tensorflow:loss = 130295140000.0, step = 34301 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.583\n",
      "INFO:tensorflow:loss = 53307460000.0, step = 34401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.984\n",
      "INFO:tensorflow:loss = 29322760000.0, step = 34501 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.321\n",
      "INFO:tensorflow:loss = 169641250000.0, step = 34601 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.402\n",
      "INFO:tensorflow:loss = 70082300000.0, step = 34701 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.167\n",
      "INFO:tensorflow:loss = 125238440000.0, step = 34801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.547\n",
      "INFO:tensorflow:loss = 182258160000.0, step = 34901 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.184\n",
      "INFO:tensorflow:loss = 71069620000.0, step = 35001 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.668\n",
      "INFO:tensorflow:loss = 38811156000.0, step = 35101 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.621\n",
      "INFO:tensorflow:loss = 65858724000.0, step = 35201 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36150550000.0, step = 35301 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.558\n",
      "INFO:tensorflow:loss = 23488274000.0, step = 35401 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.291\n",
      "INFO:tensorflow:loss = 59710992000.0, step = 35501 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.389\n",
      "INFO:tensorflow:loss = 41971425000.0, step = 35601 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.105\n",
      "INFO:tensorflow:loss = 59232660000.0, step = 35701 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.9\n",
      "INFO:tensorflow:loss = 38798455000.0, step = 35801 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.888\n",
      "INFO:tensorflow:loss = 50425315000.0, step = 35901 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.209\n",
      "INFO:tensorflow:loss = 60458360000.0, step = 36001 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.724\n",
      "INFO:tensorflow:loss = 146645990000.0, step = 36101 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.635\n",
      "INFO:tensorflow:loss = 25951300000.0, step = 36201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.973\n",
      "INFO:tensorflow:loss = 55602934000.0, step = 36301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.627\n",
      "INFO:tensorflow:loss = 27556547000.0, step = 36401 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.235\n",
      "INFO:tensorflow:loss = 33535154000.0, step = 36501 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.513\n",
      "INFO:tensorflow:loss = 89403160000.0, step = 36601 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.484\n",
      "INFO:tensorflow:loss = 97235960000.0, step = 36701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.492\n",
      "INFO:tensorflow:loss = 51019570000.0, step = 36801 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.999\n",
      "INFO:tensorflow:loss = 23458423000.0, step = 36901 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.596\n",
      "INFO:tensorflow:loss = 120851940000.0, step = 37001 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.365\n",
      "INFO:tensorflow:loss = 65177375000.0, step = 37101 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.767\n",
      "INFO:tensorflow:loss = 72935570000.0, step = 37201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.315\n",
      "INFO:tensorflow:loss = 70974650000.0, step = 37301 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.75\n",
      "INFO:tensorflow:loss = 180028360000.0, step = 37401 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.307\n",
      "INFO:tensorflow:loss = 35266126000.0, step = 37501 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.195\n",
      "INFO:tensorflow:loss = 44159340000.0, step = 37601 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.917\n",
      "INFO:tensorflow:loss = 47863247000.0, step = 37701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.444\n",
      "INFO:tensorflow:loss = 52599570000.0, step = 37801 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.822\n",
      "INFO:tensorflow:loss = 109285430000.0, step = 37901 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.758\n",
      "INFO:tensorflow:loss = 73487010000.0, step = 38001 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.637\n",
      "INFO:tensorflow:loss = 52649673000.0, step = 38101 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.078\n",
      "INFO:tensorflow:loss = 38438580000.0, step = 38201 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.195\n",
      "INFO:tensorflow:loss = 34001990000.0, step = 38301 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.79\n",
      "INFO:tensorflow:loss = 78569350000.0, step = 38401 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.017\n",
      "INFO:tensorflow:loss = 51206060000.0, step = 38501 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.387\n",
      "INFO:tensorflow:loss = 53097060000.0, step = 38601 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.13\n",
      "INFO:tensorflow:loss = 27484946000.0, step = 38701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.463\n",
      "INFO:tensorflow:loss = 130728650000.0, step = 38801 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.031\n",
      "INFO:tensorflow:loss = 123214070000.0, step = 38901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.718\n",
      "INFO:tensorflow:loss = 61531963000.0, step = 39001 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.508\n",
      "INFO:tensorflow:loss = 79344490000.0, step = 39101 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.679\n",
      "INFO:tensorflow:loss = 23406354000.0, step = 39201 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.451\n",
      "INFO:tensorflow:loss = 112723030000.0, step = 39301 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.032\n",
      "INFO:tensorflow:loss = 105469890000.0, step = 39401 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.951\n",
      "INFO:tensorflow:loss = 46775935000.0, step = 39501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.933\n",
      "INFO:tensorflow:loss = 28174283000.0, step = 39601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.969\n",
      "INFO:tensorflow:loss = 46969045000.0, step = 39701 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.506\n",
      "INFO:tensorflow:loss = 103996490000.0, step = 39801 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.266\n",
      "INFO:tensorflow:loss = 39276687000.0, step = 39901 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.497\n",
      "INFO:tensorflow:loss = 81642410000.0, step = 40001 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.309\n",
      "INFO:tensorflow:loss = 96477260000.0, step = 40101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.666\n",
      "INFO:tensorflow:loss = 91772750000.0, step = 40201 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.855\n",
      "INFO:tensorflow:loss = 80931870000.0, step = 40301 (0.214 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 40371 vs previous value: 40371. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 337.895\n",
      "INFO:tensorflow:loss = 34944635000.0, step = 40401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.155\n",
      "INFO:tensorflow:loss = 75421810000.0, step = 40501 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.483\n",
      "INFO:tensorflow:loss = 43828797000.0, step = 40601 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.619\n",
      "INFO:tensorflow:loss = 25117198000.0, step = 40701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.117\n",
      "INFO:tensorflow:loss = 14348479000.0, step = 40801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.899\n",
      "INFO:tensorflow:loss = 83800285000.0, step = 40901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.171\n",
      "INFO:tensorflow:loss = 24472570000.0, step = 41001 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.074\n",
      "INFO:tensorflow:loss = 66822365000.0, step = 41101 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.898\n",
      "INFO:tensorflow:loss = 77509040000.0, step = 41201 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.335\n",
      "INFO:tensorflow:loss = 19983800000.0, step = 41301 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.39\n",
      "INFO:tensorflow:loss = 27199005000.0, step = 41401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.599\n",
      "INFO:tensorflow:loss = 50141213000.0, step = 41501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.617\n",
      "INFO:tensorflow:loss = 62781030000.0, step = 41601 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.249\n",
      "INFO:tensorflow:loss = 81408246000.0, step = 41701 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.957\n",
      "INFO:tensorflow:loss = 93520790000.0, step = 41801 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.96\n",
      "INFO:tensorflow:loss = 148076700000.0, step = 41901 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.2\n",
      "INFO:tensorflow:loss = 40244170000.0, step = 42001 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.7\n",
      "INFO:tensorflow:loss = 102851390000.0, step = 42101 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.227\n",
      "INFO:tensorflow:loss = 38841350000.0, step = 42201 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.476\n",
      "INFO:tensorflow:loss = 67017142000.0, step = 42301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.941\n",
      "INFO:tensorflow:loss = 67378570000.0, step = 42401 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.392\n",
      "INFO:tensorflow:loss = 37653823000.0, step = 42501 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 507.469\n",
      "INFO:tensorflow:loss = 70667200000.0, step = 42601 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.621\n",
      "INFO:tensorflow:loss = 24409550000.0, step = 42701 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.116\n",
      "INFO:tensorflow:loss = 128637710000.0, step = 42801 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.329\n",
      "INFO:tensorflow:loss = 42978693000.0, step = 42901 (0.208 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 389.103\n",
      "INFO:tensorflow:loss = 32170730000.0, step = 43001 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.06\n",
      "INFO:tensorflow:loss = 51006890000.0, step = 43101 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.814\n",
      "INFO:tensorflow:loss = 55261780000.0, step = 43201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.952\n",
      "INFO:tensorflow:loss = 65400287000.0, step = 43301 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.696\n",
      "INFO:tensorflow:loss = 58496565000.0, step = 43401 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.879\n",
      "INFO:tensorflow:loss = 47873870000.0, step = 43501 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.879\n",
      "INFO:tensorflow:loss = 161755400000.0, step = 43601 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.395\n",
      "INFO:tensorflow:loss = 37898236000.0, step = 43701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.912\n",
      "INFO:tensorflow:loss = 43756690000.0, step = 43801 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.105\n",
      "INFO:tensorflow:loss = 64861780000.0, step = 43901 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.396\n",
      "INFO:tensorflow:loss = 46934258000.0, step = 44001 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.896\n",
      "INFO:tensorflow:loss = 85742110000.0, step = 44101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.93\n",
      "INFO:tensorflow:loss = 24795757000.0, step = 44201 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.385\n",
      "INFO:tensorflow:loss = 100276270000.0, step = 44301 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.426\n",
      "INFO:tensorflow:loss = 39929650000.0, step = 44401 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.247\n",
      "INFO:tensorflow:loss = 98883530000.0, step = 44501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.464\n",
      "INFO:tensorflow:loss = 193398620000.0, step = 44601 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.691\n",
      "INFO:tensorflow:loss = 97593220000.0, step = 44701 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.092\n",
      "INFO:tensorflow:loss = 98975965000.0, step = 44801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.548\n",
      "INFO:tensorflow:loss = 73284660000.0, step = 44901 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.977\n",
      "INFO:tensorflow:loss = 113182610000.0, step = 45001 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.737\n",
      "INFO:tensorflow:loss = 108737820000.0, step = 45101 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.418\n",
      "INFO:tensorflow:loss = 15137502000.0, step = 45201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.235\n",
      "INFO:tensorflow:loss = 43764613000.0, step = 45301 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.035\n",
      "INFO:tensorflow:loss = 61638690000.0, step = 45401 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.096\n",
      "INFO:tensorflow:loss = 63626510000.0, step = 45501 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.459\n",
      "INFO:tensorflow:loss = 57737610000.0, step = 45601 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.74\n",
      "INFO:tensorflow:loss = 64079835000.0, step = 45701 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.621\n",
      "INFO:tensorflow:loss = 234608850000.0, step = 45801 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.415\n",
      "INFO:tensorflow:loss = 48494576000.0, step = 45901 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 500.912\n",
      "INFO:tensorflow:loss = 31003208000.0, step = 46001 (0.205 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 46010 vs previous value: 46010. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 499.643\n",
      "INFO:tensorflow:loss = 43034230000.0, step = 46101 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.582\n",
      "INFO:tensorflow:loss = 31740846000.0, step = 46201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.475\n",
      "INFO:tensorflow:loss = 35529785000.0, step = 46301 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 466.916\n",
      "INFO:tensorflow:loss = 85072224000.0, step = 46401 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.984\n",
      "INFO:tensorflow:loss = 68794660000.0, step = 46501 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.243\n",
      "INFO:tensorflow:loss = 38773785000.0, step = 46601 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.817\n",
      "INFO:tensorflow:loss = 75858330000.0, step = 46701 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.794\n",
      "INFO:tensorflow:loss = 62461424000.0, step = 46801 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.582\n",
      "INFO:tensorflow:loss = 43918280000.0, step = 46901 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.015\n",
      "INFO:tensorflow:loss = 19107830000.0, step = 47001 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.487\n",
      "INFO:tensorflow:loss = 49933574000.0, step = 47101 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.089\n",
      "INFO:tensorflow:loss = 71639730000.0, step = 47201 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.682\n",
      "INFO:tensorflow:loss = 44143160000.0, step = 47301 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.251\n",
      "INFO:tensorflow:loss = 41298244000.0, step = 47401 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.57\n",
      "INFO:tensorflow:loss = 43794780000.0, step = 47501 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.566\n",
      "INFO:tensorflow:loss = 23014513000.0, step = 47601 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.336\n",
      "INFO:tensorflow:loss = 78585420000.0, step = 47701 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.535\n",
      "INFO:tensorflow:loss = 51148784000.0, step = 47801 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.839\n",
      "INFO:tensorflow:loss = 52413936000.0, step = 47901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.102\n",
      "INFO:tensorflow:loss = 26299531000.0, step = 48001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.47\n",
      "INFO:tensorflow:loss = 94969635000.0, step = 48101 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.213\n",
      "INFO:tensorflow:loss = 9720770000.0, step = 48201 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.795\n",
      "INFO:tensorflow:loss = 75403660000.0, step = 48301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.722\n",
      "INFO:tensorflow:loss = 76295450000.0, step = 48401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.86\n",
      "INFO:tensorflow:loss = 44952306000.0, step = 48501 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.383\n",
      "INFO:tensorflow:loss = 51472937000.0, step = 48601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.057\n",
      "INFO:tensorflow:loss = 200134030000.0, step = 48701 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.667\n",
      "INFO:tensorflow:loss = 80696860000.0, step = 48801 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.328\n",
      "INFO:tensorflow:loss = 103098030000.0, step = 48901 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.1\n",
      "INFO:tensorflow:loss = 25867706000.0, step = 49001 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.079\n",
      "INFO:tensorflow:loss = 53746580000.0, step = 49101 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.444\n",
      "INFO:tensorflow:loss = 54098300000.0, step = 49201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.197\n",
      "INFO:tensorflow:loss = 25898635000.0, step = 49301 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.985\n",
      "INFO:tensorflow:loss = 95076190000.0, step = 49401 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.291\n",
      "INFO:tensorflow:loss = 52852593000.0, step = 49501 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.157\n",
      "INFO:tensorflow:loss = 53810390000.0, step = 49601 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.526\n",
      "INFO:tensorflow:loss = 54573370000.0, step = 49701 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.407\n",
      "INFO:tensorflow:loss = 55925023000.0, step = 49801 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.617\n",
      "INFO:tensorflow:loss = 59085783000.0, step = 49901 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.948\n",
      "INFO:tensorflow:loss = 68275320000.0, step = 50001 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 481.15\n",
      "INFO:tensorflow:loss = 25269666000.0, step = 50101 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.092\n",
      "INFO:tensorflow:loss = 44486955000.0, step = 50201 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.763\n",
      "INFO:tensorflow:loss = 50024305000.0, step = 50301 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.089\n",
      "INFO:tensorflow:loss = 123483210000.0, step = 50401 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.134\n",
      "INFO:tensorflow:loss = 41999810000.0, step = 50501 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 31956044000.0, step = 50601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.625\n",
      "INFO:tensorflow:loss = 42782620000.0, step = 50701 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.198\n",
      "INFO:tensorflow:loss = 81940740000.0, step = 50801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.681\n",
      "INFO:tensorflow:loss = 43091410000.0, step = 50901 (0.193 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 51000 into C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpxyg8jez1\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28541055000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressor at 0x198ddad1ec8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Erstelle eine Vorhersage-Eingabefunktion und verwende dann die Methode `.predict` aus Ihrem Schätzmodell, um eine Liste oder Vorhersagen für deine Testdaten zu erstellen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DF87D2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DF87D2C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DF87D2C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x00000198DF87D2C8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDAA1888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDAA1888>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDAA1888>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DenseFeatures.call of <tensorflow.python.feature_column.feature_column_v2.DenseFeatures object at 0x00000198DDAA1888>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD952C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD952C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD952C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD952C08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD9521C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD9521C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD9521C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DD9521C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000198DE464148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\181083~1\\AppData\\Local\\Temp\\tmpxyg8jez1\\model.ckpt-51000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "pred_gen = model.predict(predict_input_func)\n",
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Berechne die RMSE. Dies kannst du manuell machen oder wahlweise mit: [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81817.74477849716"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gut gemacht!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
